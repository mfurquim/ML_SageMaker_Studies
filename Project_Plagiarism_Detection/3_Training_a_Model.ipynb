{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plagiarism Detection Model\n",
    "\n",
    "Now that you've created training and test data, you are ready to define and train a model. Your goal in this notebook, will be to train a binary classification model that learns to label an answer file as either plagiarized or not, based on the features you provide the model.\n",
    "\n",
    "This task will be broken down into a few discrete steps:\n",
    "\n",
    "* Upload your data to S3.\n",
    "* Define a binary classification model and a training script.\n",
    "* Train your model and deploy it.\n",
    "* Evaluate your deployed classifier and answer some questions about your approach.\n",
    "\n",
    "To complete this notebook, you'll have to complete all given exercises and answer all the questions in this notebook.\n",
    "> All your tasks will be clearly labeled **EXERCISE** and questions as **QUESTION**.\n",
    "\n",
    "It will be up to you to explore different classification models and decide on a model that gives you the best performance for this dataset.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data to S3\n",
    "\n",
    "In the last notebook, you should have created two files: a `training.csv` and `test.csv` file with the features and class labels for the given corpus of plagiarized/non-plagiarized text data. \n",
    "\n",
    ">The below cells load in some AWS SageMaker libraries and creates a default bucket. After creating this bucket, you can upload your locally stored data to S3.\n",
    "\n",
    "Save your train and test `.csv` feature files, locally. To do this you can run the second notebook \"2_Plagiarism_Feature_Engineering\" in SageMaker or you can manually upload your files to this notebook using the upload icon in Jupyter Lab. Then you can upload local files to S3 by using `sagemaker_session.upload_data` and pointing directly to where the training data is saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "import sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# session and role\n",
    "sagemaker_session = sagemaker.Session()\n",
    "role = sagemaker.get_execution_role()\n",
    "\n",
    "# create an S3 bucket\n",
    "bucket = sagemaker_session.default_bucket()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Upload your training data to S3\n",
    "\n",
    "Specify the `data_dir` where you've saved your `train.csv` file. Decide on a descriptive `prefix` that defines where your data will be uploaded in the default S3 bucket. Finally, create a pointer to your training data by calling `sagemaker_session.upload_data` and passing in the required parameters. It may help to look at the [Session documentation](https://sagemaker.readthedocs.io/en/stable/session.html#sagemaker.session.Session.upload_data) or previous SageMaker code examples.\n",
    "\n",
    "You are expected to upload your entire directory. Later, the training script will only access the `train.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s3://sagemaker-us-east-1-992826950268/plagiarism\n"
     ]
    }
   ],
   "source": [
    "# should be the name of directory you created to save your features data\n",
    "data_dir = 'plagiarism_data'\n",
    "\n",
    "# set prefix, a descriptive name for a directory  \n",
    "prefix = 'plagiarism'\n",
    "\n",
    "# upload all data to S3\n",
    "input_data = sagemaker_session.upload_data(path=data_dir, bucket=bucket, key_prefix=prefix)\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test cell\n",
    "\n",
    "Test that your data has been successfully uploaded. The below cell prints out the items in your S3 bucket and will throw an error if it is empty. You should see the contents of your `data_dir` and perhaps some checkpoints. If you see any other files listed, then you may have some old model files that you can delete via the S3 console (though, additional files shouldn't affect the performance of model developed in this notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plagiarism/test.csv\n",
      "plagiarism/train.csv\n",
      "pytorch-training-2022-05-11-02-08-32-273/debug-output/training_job_end.ts\n",
      "pytorch-training-2022-05-11-02-08-32-273/profiler-output/framework/training_job_end.ts\n",
      "pytorch-training-2022-05-11-02-08-32-273/profiler-output/system/incremental/2022051102/1652235120.algo-1.json\n",
      "pytorch-training-2022-05-11-02-08-32-273/profiler-output/system/incremental/2022051102/1652235180.algo-1.json\n",
      "pytorch-training-2022-05-11-02-08-32-273/profiler-output/system/incremental/2022051102/1652235240.algo-1.json\n",
      "pytorch-training-2022-05-11-02-08-32-273/profiler-output/system/training_job_end.ts\n",
      "pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-report.html\n",
      "pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-report.ipynb\n",
      "pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/BatchSize.json\n",
      "pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/CPUBottleneck.json\n",
      "pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/Dataloader.json\n",
      "pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/GPUMemoryIncrease.json\n",
      "pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/IOBottleneck.json\n",
      "pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/LoadBalancing.json\n",
      "pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/LowGPUUtilization.json\n",
      "pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/MaxInitializationTime.json\n",
      "pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/OverallFrameworkMetrics.json\n",
      "pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/OverallSystemUsage.json\n",
      "pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/StepOutlier.json\n",
      "pytorch-training-2022-05-11-02-08-32-273/source/sourcedir.tar.gz\n",
      "pytorch-training-2022-05-11-02-20-20-627/debug-output/training_job_end.ts\n",
      "pytorch-training-2022-05-11-02-20-20-627/profiler-output/framework/training_job_end.ts\n",
      "pytorch-training-2022-05-11-02-20-20-627/profiler-output/system/incremental/2022051102/1652235780.algo-1.json\n",
      "pytorch-training-2022-05-11-02-20-20-627/profiler-output/system/incremental/2022051102/1652235840.algo-1.json\n",
      "pytorch-training-2022-05-11-02-20-20-627/profiler-output/system/incremental/2022051102/1652235900.algo-1.json\n",
      "pytorch-training-2022-05-11-02-20-20-627/profiler-output/system/training_job_end.ts\n",
      "pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-report.html\n",
      "pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-report.ipynb\n",
      "pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/BatchSize.json\n",
      "pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/CPUBottleneck.json\n",
      "pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/Dataloader.json\n",
      "pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/GPUMemoryIncrease.json\n",
      "pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/IOBottleneck.json\n",
      "pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/LoadBalancing.json\n",
      "pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/LowGPUUtilization.json\n",
      "pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/MaxInitializationTime.json\n",
      "pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/OverallFrameworkMetrics.json\n",
      "pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/OverallSystemUsage.json\n",
      "pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/StepOutlier.json\n",
      "pytorch-training-2022-05-11-02-20-20-627/source/sourcedir.tar.gz\n",
      "pytorch-training-2022-05-11-02-25-44-335/debug-output/training_job_end.ts\n",
      "pytorch-training-2022-05-11-02-25-44-335/profiler-output/framework/training_job_end.ts\n",
      "pytorch-training-2022-05-11-02-25-44-335/profiler-output/system/incremental/2022051102/1652236080.algo-1.json\n",
      "pytorch-training-2022-05-11-02-25-44-335/profiler-output/system/incremental/2022051102/1652236140.algo-1.json\n",
      "pytorch-training-2022-05-11-02-25-44-335/profiler-output/system/incremental/2022051102/1652236200.algo-1.json\n",
      "pytorch-training-2022-05-11-02-25-44-335/profiler-output/system/training_job_end.ts\n",
      "pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-report.html\n",
      "pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-report.ipynb\n",
      "pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/BatchSize.json\n",
      "pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/CPUBottleneck.json\n",
      "pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/Dataloader.json\n",
      "pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/GPUMemoryIncrease.json\n",
      "pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/IOBottleneck.json\n",
      "pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/LoadBalancing.json\n",
      "pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/LowGPUUtilization.json\n",
      "pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/MaxInitializationTime.json\n",
      "pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/OverallFrameworkMetrics.json\n",
      "pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/OverallSystemUsage.json\n",
      "pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/StepOutlier.json\n",
      "pytorch-training-2022-05-11-02-25-44-335/source/sourcedir.tar.gz\n",
      "pytorch-training-2022-05-11-02-25-51-667/debug-output/training_job_end.ts\n",
      "pytorch-training-2022-05-11-02-25-51-667/profiler-output/framework/training_job_end.ts\n",
      "pytorch-training-2022-05-11-02-25-51-667/profiler-output/system/incremental/2022051102/1652236080.algo-1.json\n",
      "pytorch-training-2022-05-11-02-25-51-667/profiler-output/system/incremental/2022051102/1652236140.algo-1.json\n",
      "pytorch-training-2022-05-11-02-25-51-667/profiler-output/system/incremental/2022051102/1652236200.algo-1.json\n",
      "pytorch-training-2022-05-11-02-25-51-667/profiler-output/system/training_job_end.ts\n",
      "pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-report.html\n",
      "pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-report.ipynb\n",
      "pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/BatchSize.json\n",
      "pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/CPUBottleneck.json\n",
      "pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/Dataloader.json\n",
      "pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/GPUMemoryIncrease.json\n",
      "pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/IOBottleneck.json\n",
      "pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/LoadBalancing.json\n",
      "pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/LowGPUUtilization.json\n",
      "pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/MaxInitializationTime.json\n",
      "pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/OverallFrameworkMetrics.json\n",
      "pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/OverallSystemUsage.json\n",
      "pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/StepOutlier.json\n",
      "pytorch-training-2022-05-11-02-25-51-667/source/sourcedir.tar.gz\n",
      "pytorch-training-2022-05-11-02-32-20-920/debug-output/collections/000000000/worker_0_collections.json\n",
      "pytorch-training-2022-05-11-02-32-20-920/debug-output/training_job_end.ts\n",
      "pytorch-training-2022-05-11-02-32-20-920/profiler-output/framework/training_job_end.ts\n",
      "pytorch-training-2022-05-11-02-32-20-920/profiler-output/system/incremental/2022051102/1652236440.algo-1.json\n",
      "pytorch-training-2022-05-11-02-32-20-920/profiler-output/system/incremental/2022051102/1652236500.algo-1.json\n",
      "pytorch-training-2022-05-11-02-32-20-920/profiler-output/system/incremental/2022051102/1652236560.algo-1.json\n",
      "pytorch-training-2022-05-11-02-32-20-920/profiler-output/system/training_job_end.ts\n",
      "pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-report.html\n",
      "pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-report.ipynb\n",
      "pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/BatchSize.json\n",
      "pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/CPUBottleneck.json\n",
      "pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/Dataloader.json\n",
      "pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/GPUMemoryIncrease.json\n",
      "pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/IOBottleneck.json\n",
      "pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/LoadBalancing.json\n",
      "pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/LowGPUUtilization.json\n",
      "pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/MaxInitializationTime.json\n",
      "pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/OverallFrameworkMetrics.json\n",
      "pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/OverallSystemUsage.json\n",
      "pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/StepOutlier.json\n",
      "pytorch-training-2022-05-11-02-32-20-920/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2022-05-11-02-01-01-215/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2022-05-11-02-01-21-130/debug-output/training_job_end.ts\n",
      "sagemaker-pytorch-2022-05-11-02-01-21-130/profiler-output/framework/training_job_end.ts\n",
      "sagemaker-pytorch-2022-05-11-02-01-21-130/profiler-output/system/incremental/2022051102/1652234580.algo-1.json\n",
      "sagemaker-pytorch-2022-05-11-02-01-21-130/profiler-output/system/incremental/2022051102/1652234640.algo-1.json\n",
      "sagemaker-pytorch-2022-05-11-02-01-21-130/profiler-output/system/training_job_end.ts\n",
      "sagemaker-pytorch-2022-05-11-02-01-21-130/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2022-05-11-02-43-08-585/debug-output/training_job_end.ts\n",
      "sagemaker-pytorch-2022-05-11-02-43-08-585/output/model.tar.gz\n",
      "sagemaker-pytorch-2022-05-11-02-43-08-585/profiler-output/framework/training_job_end.ts\n",
      "sagemaker-pytorch-2022-05-11-02-43-08-585/profiler-output/system/incremental/2022051102/1652237100.algo-1.json\n",
      "sagemaker-pytorch-2022-05-11-02-43-08-585/profiler-output/system/training_job_end.ts\n",
      "sagemaker-pytorch-2022-05-11-02-43-08-585/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/debug-output/training_job_end.ts\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/output/model.tar.gz\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/profiler-output/framework/training_job_end.ts\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/profiler-output/system/incremental/2022051102/1652237160.algo-1.json\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/profiler-output/system/incremental/2022051102/1652237220.algo-1.json\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/profiler-output/system/training_job_end.ts\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-report.html\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-report.ipynb\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/BatchSize.json\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/CPUBottleneck.json\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/Dataloader.json\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/GPUMemoryIncrease.json\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/IOBottleneck.json\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/LoadBalancing.json\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/LowGPUUtilization.json\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/MaxInitializationTime.json\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/OverallFrameworkMetrics.json\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/OverallSystemUsage.json\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/StepOutlier.json\n",
      "sagemaker-pytorch-2022-05-11-02-44-34-046/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2022-05-11-02-50-59-410/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2022-05-11-03-20-08-071/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/debug-output/training_job_end.ts\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/output/model.tar.gz\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/profiler-output/framework/training_job_end.ts\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/profiler-output/system/incremental/2022051104/1652242740.algo-1.json\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/profiler-output/system/incremental/2022051104/1652242800.algo-1.json\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/profiler-output/system/training_job_end.ts\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-report.html\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-report.ipynb\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/BatchSize.json\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/CPUBottleneck.json\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/Dataloader.json\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/GPUMemoryIncrease.json\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/IOBottleneck.json\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/LoadBalancing.json\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/LowGPUUtilization.json\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/MaxInitializationTime.json\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/OverallFrameworkMetrics.json\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/OverallSystemUsage.json\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/StepOutlier.json\n",
      "sagemaker-pytorch-2022-05-11-04-17-52-619/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/debug-output/training_job_end.ts\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/output/model.tar.gz\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/profiler-output/framework/training_job_end.ts\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/profiler-output/system/incremental/2022051104/1652244180.algo-1.json\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/profiler-output/system/incremental/2022051104/1652244240.algo-1.json\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/profiler-output/system/training_job_end.ts\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-report.html\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-report.ipynb\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/BatchSize.json\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/CPUBottleneck.json\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/Dataloader.json\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/GPUMemoryIncrease.json\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/IOBottleneck.json\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/LoadBalancing.json\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/LowGPUUtilization.json\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/MaxInitializationTime.json\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/OverallFrameworkMetrics.json\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/OverallSystemUsage.json\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/StepOutlier.json\n",
      "sagemaker-pytorch-2022-05-11-04-41-17-625/source/sourcedir.tar.gz\n",
      "sagemaker-pytorch-2022-05-11-04-45-01-079/sourcedir.tar.gz\n",
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# confirm that data is in S3 bucket\n",
    "empty_check = []\n",
    "for obj in boto3.resource('s3').Bucket(bucket).objects.all():\n",
    "    empty_check.append(obj.key)\n",
    "    print(obj.key)\n",
    "\n",
    "assert len(empty_check) !=0, 'S3 bucket is empty.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Modeling\n",
    "\n",
    "Now that you've uploaded your training data, it's time to define and train a model!\n",
    "\n",
    "The type of model you create is up to you. For a binary classification task, you can choose to go one of three routes:\n",
    "* Use a built-in classification algorithm, like LinearLearner.\n",
    "* Define a custom Scikit-learn classifier, a comparison of models can be found [here](https://scikit-learn.org/stable/auto_examples/classification/plot_classifier_comparison.html).\n",
    "* Define a custom PyTorch neural network classifier. \n",
    "\n",
    "It will be up to you to test out a variety of models and choose the best one. Your project will be graded on the accuracy of your final model. \n",
    " \n",
    "---\n",
    "\n",
    "## EXERCISE: Complete a training script \n",
    "\n",
    "To implement a custom classifier, you'll need to complete a `train.py` script. You've been given the folders `source_sklearn` and `source_pytorch` which hold starting code for a custom Scikit-learn model and a PyTorch model, respectively. Each directory has a `train.py` training script. To complete this project **you only need to complete one of these scripts**; the script that is responsible for training your final model.\n",
    "\n",
    "A typical training script:\n",
    "* Loads training data from a specified directory\n",
    "* Parses any training & model hyperparameters (ex. nodes in a neural network, training epochs, etc.)\n",
    "* Instantiates a model of your design, with any specified hyperparams\n",
    "* Trains that model \n",
    "* Finally, saves the model so that it can be hosted/deployed, later\n",
    "\n",
    "### Defining and training a model\n",
    "Much of the training script code is provided for you. Almost all of your work will be done in the `if __name__ == '__main__':` section. To complete a `train.py` file, you will:\n",
    "1. Import any extra libraries you need\n",
    "2. Define any additional model training hyperparameters using `parser.add_argument`\n",
    "2. Define a model in the `if __name__ == '__main__':` section\n",
    "3. Train the model in that same section\n",
    "\n",
    "Below, you can use `!pygmentize` to display an existing `train.py` file. Read through the code; all of your tasks are marked with `TODO` comments. \n",
    "\n",
    "**Note: If you choose to create a custom PyTorch model, you will be responsible for defining the model in the `model.py` file,** and a `predict.py` file is provided. If you choose to use Scikit-learn, you only need a `train.py` file; you may import a classifier from the `sklearn` library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36margparse\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mjson\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mos\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mpandas\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36mpd\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36moptim\u001b[39;49;00m \u001b[34mas\u001b[39;49;00m \u001b[04m\u001b[36moptim\u001b[39;49;00m\n",
      "\u001b[34mimport\u001b[39;49;00m \u001b[04m\u001b[36mtorch\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mutils\u001b[39;49;00m\u001b[04m\u001b[36m.\u001b[39;49;00m\u001b[04m\u001b[36mdata\u001b[39;49;00m\n",
      "\n",
      "\u001b[37m# imports the model in model.py by name\u001b[39;49;00m\n",
      "\u001b[34mfrom\u001b[39;49;00m \u001b[04m\u001b[36mmodel\u001b[39;49;00m \u001b[34mimport\u001b[39;49;00m BinaryClassifier\n",
      "\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mmodel_fn\u001b[39;49;00m(model_dir):\n",
      "    \u001b[33m\"\"\"Load the PyTorch model from the `model_dir` directory.\"\"\"\u001b[39;49;00m\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mLoading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    \u001b[37m# First, load the parameters used to create the model.\u001b[39;49;00m\n",
      "    model_info = {}\n",
      "    model_info_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_info.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_info_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        model_info = torch.load(f)\n",
      "\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mmodel_info: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(model_info))\n",
      "\n",
      "    \u001b[37m# Determine the device and construct the model.\u001b[39;49;00m\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    model = BinaryClassifier(model_info[\u001b[33m'\u001b[39;49;00m\u001b[33minput_features\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], model_info[\u001b[33m'\u001b[39;49;00m\u001b[33mhidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m], model_info[\u001b[33m'\u001b[39;49;00m\u001b[33moutput_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "\n",
      "    \u001b[37m# Load the stored model parameters.\u001b[39;49;00m\n",
      "    model_path = os.path.join(model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_path, \u001b[33m'\u001b[39;49;00m\u001b[33mrb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        model.load_state_dict(torch.load(f))\n",
      "\n",
      "    \u001b[37m# set to eval mode, could use no_grad\u001b[39;49;00m\n",
      "    model.to(device).eval()\n",
      "\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mDone loading model.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[34mreturn\u001b[39;49;00m model\n",
      "\n",
      "\u001b[37m# Gets training data in batches from the train.csv file\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32m_get_train_data_loader\u001b[39;49;00m(batch_size, training_dir):\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mGet train data loader.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "\n",
      "    train_data = pd.read_csv(os.path.join(training_dir, \u001b[33m\"\u001b[39;49;00m\u001b[33mtrain.csv\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m), header=\u001b[34mNone\u001b[39;49;00m, names=\u001b[34mNone\u001b[39;49;00m)\n",
      "\n",
      "    train_y = torch.from_numpy(train_data[[\u001b[34m0\u001b[39;49;00m]].values).float().squeeze()\n",
      "    train_x = torch.from_numpy(train_data.drop([\u001b[34m0\u001b[39;49;00m], axis=\u001b[34m1\u001b[39;49;00m).values).float()\n",
      "\n",
      "    train_ds = torch.utils.data.TensorDataset(train_x, train_y)\n",
      "\n",
      "    \u001b[34mreturn\u001b[39;49;00m torch.utils.data.DataLoader(train_ds, batch_size=batch_size)\n",
      "\n",
      "\n",
      "\u001b[37m# Provided training function\u001b[39;49;00m\n",
      "\u001b[34mdef\u001b[39;49;00m \u001b[32mtrain\u001b[39;49;00m(model, train_loader, epochs, criterion, optimizer, device):\n",
      "    \u001b[33m\"\"\"\u001b[39;49;00m\n",
      "\u001b[33m    This is the training method that is called by the PyTorch training script. The parameters\u001b[39;49;00m\n",
      "\u001b[33m    passed are as follows:\u001b[39;49;00m\n",
      "\u001b[33m    model        - The PyTorch model that we wish to train.\u001b[39;49;00m\n",
      "\u001b[33m    train_loader - The PyTorch DataLoader that should be used during training.\u001b[39;49;00m\n",
      "\u001b[33m    epochs       - The total number of epochs to train for.\u001b[39;49;00m\n",
      "\u001b[33m    criterion    - The loss function used for training. \u001b[39;49;00m\n",
      "\u001b[33m    optimizer    - The optimizer to use during training.\u001b[39;49;00m\n",
      "\u001b[33m    device       - Where the model and data should be loaded (gpu or cpu).\u001b[39;49;00m\n",
      "\u001b[33m    \"\"\"\u001b[39;49;00m\n",
      "    \n",
      "    \u001b[37m# training loop is provided\u001b[39;49;00m\n",
      "    \u001b[34mfor\u001b[39;49;00m epoch \u001b[35min\u001b[39;49;00m \u001b[36mrange\u001b[39;49;00m(\u001b[34m1\u001b[39;49;00m, epochs + \u001b[34m1\u001b[39;49;00m):\n",
      "        model.train() \u001b[37m# Make sure that the model is in training mode.\u001b[39;49;00m\n",
      "\n",
      "        total_loss = \u001b[34m0\u001b[39;49;00m\n",
      "\n",
      "        \u001b[34mfor\u001b[39;49;00m batch \u001b[35min\u001b[39;49;00m train_loader:\n",
      "            \u001b[37m# get data\u001b[39;49;00m\n",
      "            batch_x, batch_y = batch\n",
      "\n",
      "            batch_x = batch_x.to(device)\n",
      "            batch_y = batch_y.to(device)\n",
      "\n",
      "            optimizer.zero_grad()\n",
      "\n",
      "            \u001b[37m# get predictions from model\u001b[39;49;00m\n",
      "            y_pred = model(batch_x)\n",
      "            \n",
      "            \u001b[37m# perform backprop\u001b[39;49;00m\n",
      "            \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33my_pred (\u001b[39;49;00m\u001b[33m{\u001b[39;49;00my_pred.shape\u001b[33m}\u001b[39;49;00m\u001b[33m):\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m{\u001b[39;49;00my_pred\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "            \u001b[36mprint\u001b[39;49;00m(\u001b[33mf\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m\u001b[33mbatch_y (\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbatch_y.shape\u001b[33m}\u001b[39;49;00m\u001b[33m):\u001b[39;49;00m\u001b[33m\\n\u001b[39;49;00m\u001b[33m{\u001b[39;49;00mbatch_y\u001b[33m}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "            loss = criterion(y_pred, batch_y)\n",
      "            loss.backward()\n",
      "            optimizer.step()\n",
      "            \n",
      "            total_loss += loss.data.item()\n",
      "\n",
      "        \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mEpoch: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m, Loss: \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(epoch, total_loss / \u001b[36mlen\u001b[39;49;00m(train_loader)))\n",
      "\n",
      "\n",
      "\u001b[37m## Complete the main code\u001b[39;49;00m\n",
      "\u001b[34mif\u001b[39;49;00m \u001b[31m__name__\u001b[39;49;00m == \u001b[33m'\u001b[39;49;00m\u001b[33m__main__\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m:\n",
      "    \n",
      "    \u001b[37m# All of the model parameters and training parameters are sent as arguments\u001b[39;49;00m\n",
      "    \u001b[37m# when this script is executed, during a training job\u001b[39;49;00m\n",
      "    \n",
      "    \u001b[37m# Here we set up an argument parser to easily access the parameters\u001b[39;49;00m\n",
      "    parser = argparse.ArgumentParser()\n",
      "\n",
      "    \u001b[37m# SageMaker parameters, like the directories for training data and saving models; set automatically\u001b[39;49;00m\n",
      "    \u001b[37m# Do not need to change\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output-data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_OUTPUT_DATA_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--model-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_MODEL_DIR\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--data-dir\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mstr\u001b[39;49;00m, default=os.environ[\u001b[33m'\u001b[39;49;00m\u001b[33mSM_CHANNEL_TRAINING\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m])\n",
      "    \n",
      "    \u001b[37m# Training Parameters, given\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--batch-size\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33minput batch size for training (default: 10)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--epochs\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m10\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mnumber of epochs to train (default: 10)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--seed\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m42\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mS\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33mrandom seed (default: 42)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \n",
      "    \u001b[37m## Add args for the three model parameters: input_features, hidden_dim, output_dim\u001b[39;49;00m\n",
      "    \u001b[37m# Model Parameters\u001b[39;49;00m\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--input_features\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m3\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33msize of the word embeddings (default: 3)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--hidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m16\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33msize of the hidden dimension (default: 16)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    parser.add_argument(\u001b[33m'\u001b[39;49;00m\u001b[33m--output_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m, \u001b[36mtype\u001b[39;49;00m=\u001b[36mint\u001b[39;49;00m, default=\u001b[34m1\u001b[39;49;00m, metavar=\u001b[33m'\u001b[39;49;00m\u001b[33mN\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m,\n",
      "                        help=\u001b[33m'\u001b[39;49;00m\u001b[33msize of the vocabulary (default: 1)\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[37m# args holds all passed-in arguments\u001b[39;49;00m\n",
      "    args = parser.parse_args()\n",
      "\n",
      "    device = torch.device(\u001b[33m\"\u001b[39;49;00m\u001b[33mcuda\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m \u001b[34mif\u001b[39;49;00m torch.cuda.is_available() \u001b[34melse\u001b[39;49;00m \u001b[33m\"\u001b[39;49;00m\u001b[33mcpu\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m)\n",
      "    \u001b[36mprint\u001b[39;49;00m(\u001b[33m\"\u001b[39;49;00m\u001b[33mUsing device \u001b[39;49;00m\u001b[33m{}\u001b[39;49;00m\u001b[33m.\u001b[39;49;00m\u001b[33m\"\u001b[39;49;00m.format(device))\n",
      "\n",
      "    torch.manual_seed(args.seed)\n",
      "\n",
      "    \u001b[37m# Load the training data.\u001b[39;49;00m\n",
      "    train_loader = _get_train_data_loader(args.batch_size, args.data_dir)\n",
      "\n",
      "\n",
      "    \u001b[37m## --- Your code here --- ##\u001b[39;49;00m\n",
      "    \n",
      "    \u001b[37m## Build the model by passing in the input params\u001b[39;49;00m\n",
      "    \u001b[37m# To get params from the parser, call args.argument_name, ex. args.epochs or ards.hidden_dim\u001b[39;49;00m\n",
      "    \u001b[37m# Don't forget to move your model .to(device) to move to GPU , if appropriate\u001b[39;49;00m\n",
      "    model = BinaryClassifier(args.input_features, args.hidden_dim, args.output_dim).to(device)\n",
      "    \n",
      "    \u001b[37m## Define an optimizer and loss function for training\u001b[39;49;00m\n",
      "    optimizer = optim.Adam(model.parameters())\n",
      "    criterion = torch.nn.BCELoss()\n",
      "\n",
      "    \u001b[37m# Trains the model (given line of code, which calls the above training function)\u001b[39;49;00m\n",
      "    train(model, train_loader, args.epochs, criterion, optimizer, device)\n",
      "\n",
      "    \u001b[37m## Complete in the model_info by adding three argument names, the first is given\u001b[39;49;00m\n",
      "    \u001b[37m# Keep the keys of this dictionary as they are \u001b[39;49;00m\n",
      "    model_info_path = os.path.join(args.model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel_info.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_info_path, \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        model_info = {\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33minput_features\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.input_features,\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33mhidden_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.hidden_dim,\n",
      "            \u001b[33m'\u001b[39;49;00m\u001b[33moutput_dim\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m: args.output_dim,\n",
      "        }\n",
      "        torch.save(model_info, f)\n",
      "        \n",
      "    \u001b[37m## --- End of your code  --- ##\u001b[39;49;00m\n",
      "    \n",
      "\n",
      "\t\u001b[37m# Save the model parameters\u001b[39;49;00m\n",
      "    model_path = os.path.join(args.model_dir, \u001b[33m'\u001b[39;49;00m\u001b[33mmodel.pth\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m)\n",
      "    \u001b[34mwith\u001b[39;49;00m \u001b[36mopen\u001b[39;49;00m(model_path, \u001b[33m'\u001b[39;49;00m\u001b[33mwb\u001b[39;49;00m\u001b[33m'\u001b[39;49;00m) \u001b[34mas\u001b[39;49;00m f:\n",
      "        torch.save(model.cpu().state_dict(), f)\n",
      " \n"
     ]
    }
   ],
   "source": [
    "# directory can be changed to: source_sklearn or source_pytorch\n",
    "!pygmentize source_pytorch/train.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Provided code\n",
    "\n",
    "If you read the code above, you can see that the starter code includes a few things:\n",
    "* Model loading (`model_fn`) and saving code\n",
    "* Getting SageMaker's default hyperparameters\n",
    "* Loading the training data by name, `train.csv` and extracting the features and labels, `train_x`, and `train_y`\n",
    "\n",
    "If you'd like to read more about model saving with [joblib for sklearn](https://scikit-learn.org/stable/modules/model_persistence.html) or with [torch.save](https://pytorch.org/tutorials/beginner/saving_loading_models.html), click on the provided links."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Create an Estimator\n",
    "\n",
    "When a custom model is constructed in SageMaker, an entry point must be specified. This is the Python file which will be executed when the model is trained; the `train.py` function you specified above. To run a custom training script in SageMaker, construct an estimator, and fill in the appropriate constructor arguments:\n",
    "\n",
    "* **entry_point**: The path to the Python script SageMaker runs for training and prediction.\n",
    "* **source_dir**: The path to the training script directory `source_sklearn` OR `source_pytorch`.\n",
    "* **role**: Role ARN, which was specified, above.\n",
    "* **train_instance_count**: The number of training instances (should be left at 1).\n",
    "* **train_instance_type**: The type of SageMaker instance for training. Note: Because Scikit-learn does not natively support GPU training, Sagemaker Scikit-learn does not currently support training on GPU instance types.\n",
    "* **sagemaker_session**: The session used to train on Sagemaker.\n",
    "* **hyperparameters** (optional): A dictionary `{'name':value, ..}` passed to the train function as hyperparameters.\n",
    "\n",
    "Note: For a PyTorch model, there is another optional argument **framework_version**, which you can set to the latest version of PyTorch, `1.0`.\n",
    "\n",
    "## EXERCISE: Define a Scikit-learn or PyTorch estimator\n",
    "\n",
    "To import your desired estimator, use one of the following lines:\n",
    "```\n",
    "from sagemaker.sklearn.estimator import SKLearn\n",
    "```\n",
    "```\n",
    "from sagemaker.pytorch import PyTorch\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train_instance_count has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n",
      "train_instance_type has been renamed in sagemaker>=2.\n",
      "See: https://sagemaker.readthedocs.io/en/stable/v2.html for details.\n"
     ]
    }
   ],
   "source": [
    "from sagemaker.pytorch import PyTorch\n",
    "\n",
    "estimator = PyTorch(entry_point=\"train.py\",\n",
    "                    source_dir=\"source_pytorch\",\n",
    "                    role=role,\n",
    "                    framework_version='1.0',\n",
    "                    py_version='py3',\n",
    "                    train_instance_count=1,\n",
    "                    train_instance_type='ml.m4.xlarge',\n",
    "                    hyperparameters={\n",
    "                        'epochs': 42,\n",
    "                        'hidden_dim': 200,\n",
    "                    },\n",
    "                    binary_classifier_model_selection_criteria='precision_at_target_recall', # target recall\n",
    "                    target_recall=0.9 # 90% recall\n",
    "                   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Train the estimator\n",
    "\n",
    "Train your estimator on the training data stored in S3. This should create a training job that you can monitor in your SageMaker console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-05-11 04:47:14 Starting - Starting the training job...ProfilerReport-1652244434: InProgress\n",
      "...\n",
      "2022-05-11 04:47:57 Starting - Preparing the instances for training......\n",
      "2022-05-11 04:49:12 Downloading - Downloading input data...\n",
      "2022-05-11 04:49:38 Training - Downloading the training image..\n",
      "2022-05-11 04:50:09 Uploading - Uploading generated training model\u001b[34mbash: cannot set terminal process group (-1): Inappropriate ioctl for device\u001b[0m\n",
      "\u001b[34mbash: no job control in this shell\u001b[0m\n",
      "\u001b[34m2022-05-11 04:49:56,611 sagemaker-containers INFO     Imported framework sagemaker_pytorch_container.training\u001b[0m\n",
      "\u001b[34m2022-05-11 04:49:56,615 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-05-11 04:49:56,638 sagemaker_pytorch_container.training INFO     Block until all host DNS lookups succeed.\u001b[0m\n",
      "\u001b[34m2022-05-11 04:49:56,639 sagemaker_pytorch_container.training INFO     Invoking user training script.\u001b[0m\n",
      "\u001b[34m2022-05-11 04:49:57,040 sagemaker-containers INFO     Module train does not provide a setup.py. \u001b[0m\n",
      "\u001b[34mGenerating setup.py\u001b[0m\n",
      "\u001b[34m2022-05-11 04:49:57,040 sagemaker-containers INFO     Generating setup.cfg\u001b[0m\n",
      "\u001b[34m2022-05-11 04:49:57,040 sagemaker-containers INFO     Generating MANIFEST.in\u001b[0m\n",
      "\u001b[34m2022-05-11 04:49:57,041 sagemaker-containers INFO     Installing module with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m pip install -U . \u001b[0m\n",
      "\u001b[34mProcessing /opt/ml/code\u001b[0m\n",
      "\u001b[34mBuilding wheels for collected packages: train\n",
      "  Running setup.py bdist_wheel for train: started\n",
      "  Running setup.py bdist_wheel for train: finished with status 'done'\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-z2q2j5cv/wheels/35/24/16/37574d11bf9bde50616c67372a334f94fa8356bc7164af8ca3\u001b[0m\n",
      "\u001b[34mSuccessfully built train\u001b[0m\n",
      "\u001b[34mInstalling collected packages: train\u001b[0m\n",
      "\u001b[34mSuccessfully installed train-1.0.0\u001b[0m\n",
      "\u001b[34mYou are using pip version 18.1, however version 21.3.1 is available.\u001b[0m\n",
      "\u001b[34mYou should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n",
      "\u001b[34m2022-05-11 04:49:59,289 sagemaker-containers INFO     No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34m2022-05-11 04:49:59,314 sagemaker-containers INFO     Invoking user script\u001b[0m\n",
      "\u001b[34mTraining Env:\u001b[0m\n",
      "\u001b[34m{\n",
      "    \"additional_framework_parameters\": {},\n",
      "    \"channel_input_dirs\": {\n",
      "        \"training\": \"/opt/ml/input/data/training\"\n",
      "    },\n",
      "    \"current_host\": \"algo-1\",\n",
      "    \"framework_module\": \"sagemaker_pytorch_container.training:main\",\n",
      "    \"hosts\": [\n",
      "        \"algo-1\"\n",
      "    ],\n",
      "    \"hyperparameters\": {\n",
      "        \"epochs\": 42,\n",
      "        \"hidden_dim\": 200\n",
      "    },\n",
      "    \"input_config_dir\": \"/opt/ml/input/config\",\n",
      "    \"input_data_config\": {\n",
      "        \"training\": {\n",
      "            \"TrainingInputMode\": \"File\",\n",
      "            \"S3DistributionType\": \"FullyReplicated\",\n",
      "            \"RecordWrapperType\": \"None\"\n",
      "        }\n",
      "    },\n",
      "    \"input_dir\": \"/opt/ml/input\",\n",
      "    \"is_master\": true,\n",
      "    \"job_name\": \"sagemaker-pytorch-2022-05-11-04-47-14-375\",\n",
      "    \"log_level\": 20,\n",
      "    \"master_hostname\": \"algo-1\",\n",
      "    \"model_dir\": \"/opt/ml/model\",\n",
      "    \"module_dir\": \"s3://sagemaker-us-east-1-992826950268/sagemaker-pytorch-2022-05-11-04-47-14-375/source/sourcedir.tar.gz\",\n",
      "    \"module_name\": \"train\",\n",
      "    \"network_interface_name\": \"eth0\",\n",
      "    \"num_cpus\": 4,\n",
      "    \"num_gpus\": 0,\n",
      "    \"output_data_dir\": \"/opt/ml/output/data\",\n",
      "    \"output_dir\": \"/opt/ml/output\",\n",
      "    \"output_intermediate_dir\": \"/opt/ml/output/intermediate\",\n",
      "    \"resource_config\": {\n",
      "        \"current_host\": \"algo-1\",\n",
      "        \"current_instance_type\": \"ml.m4.xlarge\",\n",
      "        \"current_group_name\": \"homogeneousCluster\",\n",
      "        \"hosts\": [\n",
      "            \"algo-1\"\n",
      "        ],\n",
      "        \"instance_groups\": [\n",
      "            {\n",
      "                \"instance_group_name\": \"homogeneousCluster\",\n",
      "                \"instance_type\": \"ml.m4.xlarge\",\n",
      "                \"hosts\": [\n",
      "                    \"algo-1\"\n",
      "                ]\n",
      "            }\n",
      "        ],\n",
      "        \"network_interface_name\": \"eth0\"\n",
      "    },\n",
      "    \"user_entry_point\": \"train.py\"\u001b[0m\n",
      "\u001b[34m}\u001b[0m\n",
      "\u001b[34mEnvironment variables:\u001b[0m\n",
      "\u001b[34mSM_HOSTS=[\"algo-1\"]\u001b[0m\n",
      "\u001b[34mSM_NETWORK_INTERFACE_NAME=eth0\u001b[0m\n",
      "\u001b[34mSM_HPS={\"epochs\":42,\"hidden_dim\":200}\u001b[0m\n",
      "\u001b[34mSM_USER_ENTRY_POINT=train.py\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_PARAMS={}\u001b[0m\n",
      "\u001b[34mSM_RESOURCE_CONFIG={\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"}\u001b[0m\n",
      "\u001b[34mSM_INPUT_DATA_CONFIG={\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}}\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DATA_DIR=/opt/ml/output/data\u001b[0m\n",
      "\u001b[34mSM_CHANNELS=[\"training\"]\u001b[0m\n",
      "\u001b[34mSM_CURRENT_HOST=algo-1\u001b[0m\n",
      "\u001b[34mSM_MODULE_NAME=train\u001b[0m\n",
      "\u001b[34mSM_LOG_LEVEL=20\u001b[0m\n",
      "\u001b[34mSM_FRAMEWORK_MODULE=sagemaker_pytorch_container.training:main\u001b[0m\n",
      "\u001b[34mSM_INPUT_DIR=/opt/ml/input\u001b[0m\n",
      "\u001b[34mSM_INPUT_CONFIG_DIR=/opt/ml/input/config\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_DIR=/opt/ml/output\u001b[0m\n",
      "\u001b[34mSM_NUM_CPUS=4\u001b[0m\n",
      "\u001b[34mSM_NUM_GPUS=0\u001b[0m\n",
      "\u001b[34mSM_MODEL_DIR=/opt/ml/model\u001b[0m\n",
      "\u001b[34mSM_MODULE_DIR=s3://sagemaker-us-east-1-992826950268/sagemaker-pytorch-2022-05-11-04-47-14-375/source/sourcedir.tar.gz\u001b[0m\n",
      "\u001b[34mSM_TRAINING_ENV={\"additional_framework_parameters\":{},\"channel_input_dirs\":{\"training\":\"/opt/ml/input/data/training\"},\"current_host\":\"algo-1\",\"framework_module\":\"sagemaker_pytorch_container.training:main\",\"hosts\":[\"algo-1\"],\"hyperparameters\":{\"epochs\":42,\"hidden_dim\":200},\"input_config_dir\":\"/opt/ml/input/config\",\"input_data_config\":{\"training\":{\"RecordWrapperType\":\"None\",\"S3DistributionType\":\"FullyReplicated\",\"TrainingInputMode\":\"File\"}},\"input_dir\":\"/opt/ml/input\",\"is_master\":true,\"job_name\":\"sagemaker-pytorch-2022-05-11-04-47-14-375\",\"log_level\":20,\"master_hostname\":\"algo-1\",\"model_dir\":\"/opt/ml/model\",\"module_dir\":\"s3://sagemaker-us-east-1-992826950268/sagemaker-pytorch-2022-05-11-04-47-14-375/source/sourcedir.tar.gz\",\"module_name\":\"train\",\"network_interface_name\":\"eth0\",\"num_cpus\":4,\"num_gpus\":0,\"output_data_dir\":\"/opt/ml/output/data\",\"output_dir\":\"/opt/ml/output\",\"output_intermediate_dir\":\"/opt/ml/output/intermediate\",\"resource_config\":{\"current_group_name\":\"homogeneousCluster\",\"current_host\":\"algo-1\",\"current_instance_type\":\"ml.m4.xlarge\",\"hosts\":[\"algo-1\"],\"instance_groups\":[{\"hosts\":[\"algo-1\"],\"instance_group_name\":\"homogeneousCluster\",\"instance_type\":\"ml.m4.xlarge\"}],\"network_interface_name\":\"eth0\"},\"user_entry_point\":\"train.py\"}\u001b[0m\n",
      "\u001b[34mSM_USER_ARGS=[\"--epochs\",\"42\",\"--hidden_dim\",\"200\"]\u001b[0m\n",
      "\u001b[34mSM_OUTPUT_INTERMEDIATE_DIR=/opt/ml/output/intermediate\u001b[0m\n",
      "\u001b[34mSM_CHANNEL_TRAINING=/opt/ml/input/data/training\u001b[0m\n",
      "\u001b[34mSM_HP_EPOCHS=42\u001b[0m\n",
      "\u001b[34mSM_HP_HIDDEN_DIM=200\u001b[0m\n",
      "\u001b[34mPYTHONPATH=/usr/local/bin:/usr/lib/python36.zip:/usr/lib/python3.6:/usr/lib/python3.6/lib-dynload:/usr/local/lib/python3.6/dist-packages:/usr/lib/python3/dist-packages\u001b[0m\n",
      "\u001b[34mInvoking script with the following command:\u001b[0m\n",
      "\u001b[34m/usr/bin/python -m train --epochs 42 --hidden_dim 200\u001b[0m\n",
      "\u001b[34mUsing device cpu.\u001b[0m\n",
      "\u001b[34mGet train data loader.\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5117],\n",
      "        [0.5108],\n",
      "        [0.5121],\n",
      "        [0.4942],\n",
      "        [0.5511],\n",
      "        [0.4996],\n",
      "        [0.4505],\n",
      "        [0.5208],\n",
      "        [0.4405],\n",
      "        [0.5191]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4738],\n",
      "        [0.5127],\n",
      "        [0.5317],\n",
      "        [0.4803],\n",
      "        [0.5070],\n",
      "        [0.5165],\n",
      "        [0.5059],\n",
      "        [0.5087],\n",
      "        [0.5109],\n",
      "        [0.5226]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4942],\n",
      "        [0.4818],\n",
      "        [0.5025],\n",
      "        [0.5209],\n",
      "        [0.5177],\n",
      "        [0.5289],\n",
      "        [0.4974],\n",
      "        [0.5290],\n",
      "        [0.4908],\n",
      "        [0.5849]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5130],\n",
      "        [0.5310],\n",
      "        [0.5602],\n",
      "        [0.5487],\n",
      "        [0.5269],\n",
      "        [0.5133],\n",
      "        [0.4982],\n",
      "        [0.4975],\n",
      "        [0.5274],\n",
      "        [0.5278]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5483],\n",
      "        [0.5062],\n",
      "        [0.5364],\n",
      "        [0.5405],\n",
      "        [0.5215],\n",
      "        [0.5334],\n",
      "        [0.5725],\n",
      "        [0.4789],\n",
      "        [0.5434],\n",
      "        [0.4992]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5793],\n",
      "        [0.5182],\n",
      "        [0.4937],\n",
      "        [0.4846],\n",
      "        [0.5511],\n",
      "        [0.5402],\n",
      "        [0.4883],\n",
      "        [0.5329],\n",
      "        [0.5698],\n",
      "        [0.5399]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5163],\n",
      "        [0.5045],\n",
      "        [0.5005],\n",
      "        [0.5068],\n",
      "        [0.5479],\n",
      "        [0.5109],\n",
      "        [0.5496],\n",
      "        [0.5497],\n",
      "        [0.5429],\n",
      "        [0.5166]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 1, Loss: 0.6764385785375323\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5363],\n",
      "        [0.5231],\n",
      "        [0.5188],\n",
      "        [0.5315],\n",
      "        [0.5514],\n",
      "        [0.5771],\n",
      "        [0.5654],\n",
      "        [0.5363],\n",
      "        [0.5431],\n",
      "        [0.5588]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6208],\n",
      "        [0.5436],\n",
      "        [0.5182],\n",
      "        [0.5605],\n",
      "        [0.5829],\n",
      "        [0.5228],\n",
      "        [0.5353],\n",
      "        [0.5458],\n",
      "        [0.5257],\n",
      "        [0.5528]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5257],\n",
      "        [0.5833],\n",
      "        [0.6065],\n",
      "        [0.5436],\n",
      "        [0.5437],\n",
      "        [0.5691],\n",
      "        [0.5502],\n",
      "        [0.5302],\n",
      "        [0.5818],\n",
      "        [0.6178]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5629],\n",
      "        [0.5124],\n",
      "        [0.5648],\n",
      "        [0.5597],\n",
      "        [0.5169],\n",
      "        [0.5151],\n",
      "        [0.5468],\n",
      "        [0.5602],\n",
      "        [0.5779],\n",
      "        [0.5092]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5791],\n",
      "        [0.5208],\n",
      "        [0.5300],\n",
      "        [0.5656],\n",
      "        [0.5080],\n",
      "        [0.6112],\n",
      "        [0.6426],\n",
      "        [0.5744],\n",
      "        [0.5658],\n",
      "        [0.5622]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6026],\n",
      "        [0.5544],\n",
      "        [0.6164],\n",
      "        [0.5064],\n",
      "        [0.6440],\n",
      "        [0.5957],\n",
      "        [0.5368],\n",
      "        [0.5331],\n",
      "        [0.6297],\n",
      "        [0.5377]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6062],\n",
      "        [0.5569],\n",
      "        [0.5065],\n",
      "        [0.5535],\n",
      "        [0.5503],\n",
      "        [0.5419],\n",
      "        [0.5737],\n",
      "        [0.5373],\n",
      "        [0.5233],\n",
      "        [0.5561]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 2, Loss: 0.6559727532523019\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5583],\n",
      "        [0.5915],\n",
      "        [0.5651],\n",
      "        [0.5288],\n",
      "        [0.5468],\n",
      "        [0.6241],\n",
      "        [0.5503],\n",
      "        [0.6529],\n",
      "        [0.5585],\n",
      "        [0.6293]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7105],\n",
      "        [0.5368],\n",
      "        [0.5381],\n",
      "        [0.5283],\n",
      "        [0.5696],\n",
      "        [0.5616],\n",
      "        [0.5525],\n",
      "        [0.5537],\n",
      "        [0.5610],\n",
      "        [0.5451]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5549],\n",
      "        [0.5519],\n",
      "        [0.5884],\n",
      "        [0.6008],\n",
      "        [0.5428],\n",
      "        [0.5296],\n",
      "        [0.5728],\n",
      "        [0.5417],\n",
      "        [0.6782],\n",
      "        [0.6220]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5166],\n",
      "        [0.5415],\n",
      "        [0.6187],\n",
      "        [0.6327],\n",
      "        [0.5659],\n",
      "        [0.5707],\n",
      "        [0.5605],\n",
      "        [0.5808],\n",
      "        [0.6132],\n",
      "        [0.5961]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6701],\n",
      "        [0.5308],\n",
      "        [0.5320],\n",
      "        [0.5116],\n",
      "        [0.5546],\n",
      "        [0.6199],\n",
      "        [0.6983],\n",
      "        [0.5461],\n",
      "        [0.5865],\n",
      "        [0.6261]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5979],\n",
      "        [0.5656],\n",
      "        [0.5908],\n",
      "        [0.6490],\n",
      "        [0.6545],\n",
      "        [0.6675],\n",
      "        [0.5792],\n",
      "        [0.5819],\n",
      "        [0.6607],\n",
      "        [0.6380]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5420],\n",
      "        [0.5545],\n",
      "        [0.5633],\n",
      "        [0.5126],\n",
      "        [0.6502],\n",
      "        [0.5510],\n",
      "        [0.6856],\n",
      "        [0.5669],\n",
      "        [0.5421],\n",
      "        [0.5610]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 3, Loss: 0.6253721969468253\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4989],\n",
      "        [0.6327],\n",
      "        [0.6143],\n",
      "        [0.5234],\n",
      "        [0.6319],\n",
      "        [0.6870],\n",
      "        [0.7084],\n",
      "        [0.6536],\n",
      "        [0.5981],\n",
      "        [0.6206]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6497],\n",
      "        [0.5429],\n",
      "        [0.5178],\n",
      "        [0.5837],\n",
      "        [0.5730],\n",
      "        [0.5813],\n",
      "        [0.6054],\n",
      "        [0.5624],\n",
      "        [0.5583],\n",
      "        [0.5674]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5474],\n",
      "        [0.5621],\n",
      "        [0.5865],\n",
      "        [0.5433],\n",
      "        [0.5852],\n",
      "        [0.5889],\n",
      "        [0.5471],\n",
      "        [0.5788],\n",
      "        [0.6809],\n",
      "        [0.6806]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5608],\n",
      "        [0.5415],\n",
      "        [0.6331],\n",
      "        [0.6677],\n",
      "        [0.5720],\n",
      "        [0.5590],\n",
      "        [0.5773],\n",
      "        [0.5432],\n",
      "        [0.6019],\n",
      "        [0.5669]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7243],\n",
      "        [0.5754],\n",
      "        [0.5454],\n",
      "        [0.6000],\n",
      "        [0.6371],\n",
      "        [0.6623],\n",
      "        [0.7127],\n",
      "        [0.5857],\n",
      "        [0.5305],\n",
      "        [0.5877]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6135],\n",
      "        [0.5740],\n",
      "        [0.6205],\n",
      "        [0.6503],\n",
      "        [0.7453],\n",
      "        [0.7352],\n",
      "        [0.5548],\n",
      "        [0.5625],\n",
      "        [0.7184],\n",
      "        [0.7186]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6308],\n",
      "        [0.5821],\n",
      "        [0.5519],\n",
      "        [0.5402],\n",
      "        [0.6366],\n",
      "        [0.5427],\n",
      "        [0.6533],\n",
      "        [0.6037],\n",
      "        [0.5340],\n",
      "        [0.5629]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 4, Loss: 0.6001632213592529\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5538],\n",
      "        [0.6575],\n",
      "        [0.5960],\n",
      "        [0.5653],\n",
      "        [0.6333],\n",
      "        [0.7281],\n",
      "        [0.6818],\n",
      "        [0.7160],\n",
      "        [0.6583],\n",
      "        [0.6530]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7145],\n",
      "        [0.5879],\n",
      "        [0.5362],\n",
      "        [0.5065],\n",
      "        [0.5400],\n",
      "        [0.6137],\n",
      "        [0.6210],\n",
      "        [0.5719],\n",
      "        [0.5696],\n",
      "        [0.5723]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5546],\n",
      "        [0.6197],\n",
      "        [0.6796],\n",
      "        [0.6153],\n",
      "        [0.5629],\n",
      "        [0.5159],\n",
      "        [0.5533],\n",
      "        [0.5702],\n",
      "        [0.7205],\n",
      "        [0.7430]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5912],\n",
      "        [0.5837],\n",
      "        [0.6577],\n",
      "        [0.6491],\n",
      "        [0.5551],\n",
      "        [0.5579],\n",
      "        [0.5822],\n",
      "        [0.5708],\n",
      "        [0.6423],\n",
      "        [0.6441]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7523],\n",
      "        [0.5343],\n",
      "        [0.5226],\n",
      "        [0.5820],\n",
      "        [0.5733],\n",
      "        [0.7621],\n",
      "        [0.7411],\n",
      "        [0.5347],\n",
      "        [0.5273],\n",
      "        [0.6276]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6993],\n",
      "        [0.5131],\n",
      "        [0.7122],\n",
      "        [0.6873],\n",
      "        [0.7293],\n",
      "        [0.7592],\n",
      "        [0.5987],\n",
      "        [0.5179],\n",
      "        [0.7831],\n",
      "        [0.7418]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6484],\n",
      "        [0.5642],\n",
      "        [0.5365],\n",
      "        [0.5359],\n",
      "        [0.6655],\n",
      "        [0.5430],\n",
      "        [0.7235],\n",
      "        [0.5781],\n",
      "        [0.5317],\n",
      "        [0.5495]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 5, Loss: 0.5703876912593842\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5327],\n",
      "        [0.6406],\n",
      "        [0.5807],\n",
      "        [0.5707],\n",
      "        [0.6289],\n",
      "        [0.8031],\n",
      "        [0.7300],\n",
      "        [0.7371],\n",
      "        [0.6281],\n",
      "        [0.7307]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8213],\n",
      "        [0.5353],\n",
      "        [0.5031],\n",
      "        [0.5622],\n",
      "        [0.5549],\n",
      "        [0.6072],\n",
      "        [0.5742],\n",
      "        [0.5571],\n",
      "        [0.5210],\n",
      "        [0.5862]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5360],\n",
      "        [0.6177],\n",
      "        [0.6997],\n",
      "        [0.6351],\n",
      "        [0.5861],\n",
      "        [0.5549],\n",
      "        [0.5650],\n",
      "        [0.5855],\n",
      "        [0.7513],\n",
      "        [0.7741]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6137],\n",
      "        [0.6013],\n",
      "        [0.7022],\n",
      "        [0.7130],\n",
      "        [0.5406],\n",
      "        [0.5749],\n",
      "        [0.5724],\n",
      "        [0.5634],\n",
      "        [0.6518],\n",
      "        [0.6731]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7868],\n",
      "        [0.5371],\n",
      "        [0.5276],\n",
      "        [0.5807],\n",
      "        [0.6324],\n",
      "        [0.7726],\n",
      "        [0.7939],\n",
      "        [0.5604],\n",
      "        [0.5444],\n",
      "        [0.6521]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6998],\n",
      "        [0.5671],\n",
      "        [0.6494],\n",
      "        [0.6969],\n",
      "        [0.8231],\n",
      "        [0.8274],\n",
      "        [0.5478],\n",
      "        [0.5616],\n",
      "        [0.8056],\n",
      "        [0.7217]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6398],\n",
      "        [0.5535],\n",
      "        [0.5274],\n",
      "        [0.5688],\n",
      "        [0.6730],\n",
      "        [0.5616],\n",
      "        [0.7850],\n",
      "        [0.5565],\n",
      "        [0.5020],\n",
      "        [0.4772]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 6, Loss: 0.5557644707815987\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5376],\n",
      "        [0.7374],\n",
      "        [0.6331],\n",
      "        [0.5899],\n",
      "        [0.6516],\n",
      "        [0.7590],\n",
      "        [0.7575],\n",
      "        [0.7785],\n",
      "        [0.6881],\n",
      "        [0.7473]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7682],\n",
      "        [0.5731],\n",
      "        [0.5756],\n",
      "        [0.5569],\n",
      "        [0.5114],\n",
      "        [0.6741],\n",
      "        [0.6251],\n",
      "        [0.5534],\n",
      "        [0.5468],\n",
      "        [0.6126]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5240],\n",
      "        [0.6167],\n",
      "        [0.7635],\n",
      "        [0.6515],\n",
      "        [0.5506],\n",
      "        [0.4926],\n",
      "        [0.5637],\n",
      "        [0.5732],\n",
      "        [0.7840],\n",
      "        [0.8421]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6005],\n",
      "        [0.5450],\n",
      "        [0.6658],\n",
      "        [0.6885],\n",
      "        [0.5257],\n",
      "        [0.4999],\n",
      "        [0.5714],\n",
      "        [0.4918],\n",
      "        [0.6666],\n",
      "        [0.6702]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8139],\n",
      "        [0.5503],\n",
      "        [0.5356],\n",
      "        [0.5609],\n",
      "        [0.6309],\n",
      "        [0.8473],\n",
      "        [0.7714],\n",
      "        [0.5801],\n",
      "        [0.5378],\n",
      "        [0.7044]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7003],\n",
      "        [0.5094],\n",
      "        [0.6869],\n",
      "        [0.7540],\n",
      "        [0.8265],\n",
      "        [0.8208],\n",
      "        [0.5811],\n",
      "        [0.5538],\n",
      "        [0.8252],\n",
      "        [0.7877]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6322],\n",
      "        [0.5307],\n",
      "        [0.5053],\n",
      "        [0.4925],\n",
      "        [0.6863],\n",
      "        [0.4974],\n",
      "        [0.8325],\n",
      "        [0.6573],\n",
      "        [0.4980],\n",
      "        [0.5201]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 7, Loss: 0.5307669980185372\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5271],\n",
      "        [0.7460],\n",
      "        [0.5488],\n",
      "        [0.5407],\n",
      "        [0.6601],\n",
      "        [0.8391],\n",
      "        [0.7998],\n",
      "        [0.7607],\n",
      "        [0.7062],\n",
      "        [0.7188]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7502],\n",
      "        [0.5098],\n",
      "        [0.5452],\n",
      "        [0.5243],\n",
      "        [0.5905],\n",
      "        [0.6372],\n",
      "        [0.6075],\n",
      "        [0.5684],\n",
      "        [0.5840],\n",
      "        [0.5998]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5189],\n",
      "        [0.6603],\n",
      "        [0.7737],\n",
      "        [0.6481],\n",
      "        [0.5316],\n",
      "        [0.5208],\n",
      "        [0.5412],\n",
      "        [0.5663],\n",
      "        [0.8105],\n",
      "        [0.8512]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5761],\n",
      "        [0.5483],\n",
      "        [0.7080],\n",
      "        [0.7016],\n",
      "        [0.5204],\n",
      "        [0.5205],\n",
      "        [0.5040],\n",
      "        [0.5250],\n",
      "        [0.6299],\n",
      "        [0.6597]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8468],\n",
      "        [0.5712],\n",
      "        [0.5863],\n",
      "        [0.5611],\n",
      "        [0.5804],\n",
      "        [0.8573],\n",
      "        [0.8475],\n",
      "        [0.5542],\n",
      "        [0.5459],\n",
      "        [0.6551]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7079],\n",
      "        [0.5602],\n",
      "        [0.6905],\n",
      "        [0.7855],\n",
      "        [0.7678],\n",
      "        [0.8231],\n",
      "        [0.5283],\n",
      "        [0.5752],\n",
      "        [0.8015],\n",
      "        [0.8184]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6475],\n",
      "        [0.4712],\n",
      "        [0.4985],\n",
      "        [0.4463],\n",
      "        [0.7271],\n",
      "        [0.5575],\n",
      "        [0.7691],\n",
      "        [0.5783],\n",
      "        [0.4916],\n",
      "        [0.5795]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 8, Loss: 0.532148220709392\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5033],\n",
      "        [0.7773],\n",
      "        [0.4994],\n",
      "        [0.5590],\n",
      "        [0.6270],\n",
      "        [0.8037],\n",
      "        [0.7774],\n",
      "        [0.6840],\n",
      "        [0.6403],\n",
      "        [0.7475]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8769],\n",
      "        [0.5083],\n",
      "        [0.5481],\n",
      "        [0.5071],\n",
      "        [0.6081],\n",
      "        [0.5956],\n",
      "        [0.6069],\n",
      "        [0.5652],\n",
      "        [0.5879],\n",
      "        [0.5832]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4881],\n",
      "        [0.6410],\n",
      "        [0.7753],\n",
      "        [0.6674],\n",
      "        [0.5176],\n",
      "        [0.4655],\n",
      "        [0.5006],\n",
      "        [0.5674],\n",
      "        [0.8097],\n",
      "        [0.8483]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5442],\n",
      "        [0.5309],\n",
      "        [0.6707],\n",
      "        [0.7780],\n",
      "        [0.4869],\n",
      "        [0.4335],\n",
      "        [0.5555],\n",
      "        [0.5315],\n",
      "        [0.6338],\n",
      "        [0.7161]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8386],\n",
      "        [0.5284],\n",
      "        [0.4951],\n",
      "        [0.6354],\n",
      "        [0.6266],\n",
      "        [0.8272],\n",
      "        [0.8326],\n",
      "        [0.5406],\n",
      "        [0.4541],\n",
      "        [0.6600]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7139],\n",
      "        [0.4798],\n",
      "        [0.7279],\n",
      "        [0.7259],\n",
      "        [0.8420],\n",
      "        [0.8230],\n",
      "        [0.5289],\n",
      "        [0.5059],\n",
      "        [0.8479],\n",
      "        [0.7909]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6477],\n",
      "        [0.5048],\n",
      "        [0.4726],\n",
      "        [0.4742],\n",
      "        [0.7434],\n",
      "        [0.4988],\n",
      "        [0.8474],\n",
      "        [0.5813],\n",
      "        [0.4622],\n",
      "        [0.5298]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 9, Loss: 0.5101707109383175\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4698],\n",
      "        [0.7994],\n",
      "        [0.5620],\n",
      "        [0.5251],\n",
      "        [0.7067],\n",
      "        [0.8342],\n",
      "        [0.8163],\n",
      "        [0.7993],\n",
      "        [0.7038],\n",
      "        [0.7932]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8450],\n",
      "        [0.4894],\n",
      "        [0.5009],\n",
      "        [0.5323],\n",
      "        [0.4972],\n",
      "        [0.6273],\n",
      "        [0.6464],\n",
      "        [0.4916],\n",
      "        [0.5581],\n",
      "        [0.5664]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4367],\n",
      "        [0.6285],\n",
      "        [0.8133],\n",
      "        [0.6933],\n",
      "        [0.5345],\n",
      "        [0.4591],\n",
      "        [0.5689],\n",
      "        [0.5685],\n",
      "        [0.7574],\n",
      "        [0.8511]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5639],\n",
      "        [0.4682],\n",
      "        [0.6991],\n",
      "        [0.7660],\n",
      "        [0.4497],\n",
      "        [0.5032],\n",
      "        [0.4971],\n",
      "        [0.5084],\n",
      "        [0.6617],\n",
      "        [0.6792]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8978],\n",
      "        [0.5229],\n",
      "        [0.5299],\n",
      "        [0.5510],\n",
      "        [0.6747],\n",
      "        [0.8003],\n",
      "        [0.8500],\n",
      "        [0.5294],\n",
      "        [0.3953],\n",
      "        [0.6446]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8169],\n",
      "        [0.4540],\n",
      "        [0.7530],\n",
      "        [0.7720],\n",
      "        [0.8620],\n",
      "        [0.8238],\n",
      "        [0.4752],\n",
      "        [0.5174],\n",
      "        [0.8500],\n",
      "        [0.8268]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6203],\n",
      "        [0.4788],\n",
      "        [0.4933],\n",
      "        [0.4670],\n",
      "        [0.7095],\n",
      "        [0.5320],\n",
      "        [0.8039],\n",
      "        [0.5899],\n",
      "        [0.4202],\n",
      "        [0.4950]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 10, Loss: 0.48351557339940754\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4998],\n",
      "        [0.7663],\n",
      "        [0.6045],\n",
      "        [0.4836],\n",
      "        [0.6778],\n",
      "        [0.8891],\n",
      "        [0.8223],\n",
      "        [0.8330],\n",
      "        [0.7212],\n",
      "        [0.8044]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8835],\n",
      "        [0.4541],\n",
      "        [0.5088],\n",
      "        [0.4775],\n",
      "        [0.5192],\n",
      "        [0.6227],\n",
      "        [0.6496],\n",
      "        [0.5107],\n",
      "        [0.4634],\n",
      "        [0.5621]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4656],\n",
      "        [0.6474],\n",
      "        [0.7537],\n",
      "        [0.6627],\n",
      "        [0.4702],\n",
      "        [0.4992],\n",
      "        [0.5459],\n",
      "        [0.5518],\n",
      "        [0.8622],\n",
      "        [0.8762]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5608],\n",
      "        [0.4518],\n",
      "        [0.7206],\n",
      "        [0.7978],\n",
      "        [0.4833],\n",
      "        [0.4781],\n",
      "        [0.4859],\n",
      "        [0.4878],\n",
      "        [0.6052],\n",
      "        [0.6745]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9100],\n",
      "        [0.4920],\n",
      "        [0.4965],\n",
      "        [0.4871],\n",
      "        [0.6374],\n",
      "        [0.8857],\n",
      "        [0.8782],\n",
      "        [0.5354],\n",
      "        [0.4021],\n",
      "        [0.6699]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8134],\n",
      "        [0.4783],\n",
      "        [0.7378],\n",
      "        [0.7626],\n",
      "        [0.8292],\n",
      "        [0.9173],\n",
      "        [0.4559],\n",
      "        [0.4822],\n",
      "        [0.8803],\n",
      "        [0.8851]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6148],\n",
      "        [0.4992],\n",
      "        [0.4217],\n",
      "        [0.4941],\n",
      "        [0.7770],\n",
      "        [0.4338],\n",
      "        [0.8686],\n",
      "        [0.6309],\n",
      "        [0.4062],\n",
      "        [0.5079]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 11, Loss: 0.4662346584456308\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4336],\n",
      "        [0.8209],\n",
      "        [0.5568],\n",
      "        [0.5249],\n",
      "        [0.7107],\n",
      "        [0.8658],\n",
      "        [0.7035],\n",
      "        [0.8260],\n",
      "        [0.7299],\n",
      "        [0.7977]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9023],\n",
      "        [0.4557],\n",
      "        [0.5444],\n",
      "        [0.3708],\n",
      "        [0.4634],\n",
      "        [0.6126],\n",
      "        [0.6185],\n",
      "        [0.4996],\n",
      "        [0.5515],\n",
      "        [0.5768]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4530],\n",
      "        [0.6285],\n",
      "        [0.7958],\n",
      "        [0.5991],\n",
      "        [0.4842],\n",
      "        [0.4515],\n",
      "        [0.4411],\n",
      "        [0.5359],\n",
      "        [0.7812],\n",
      "        [0.9259]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5265],\n",
      "        [0.4515],\n",
      "        [0.7403],\n",
      "        [0.7648],\n",
      "        [0.4642],\n",
      "        [0.4781],\n",
      "        [0.5013],\n",
      "        [0.4361],\n",
      "        [0.6654],\n",
      "        [0.6944]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9204],\n",
      "        [0.5122],\n",
      "        [0.4794],\n",
      "        [0.5536],\n",
      "        [0.6919],\n",
      "        [0.9098],\n",
      "        [0.8896],\n",
      "        [0.5742],\n",
      "        [0.4563],\n",
      "        [0.6131]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7878],\n",
      "        [0.4269],\n",
      "        [0.7685],\n",
      "        [0.8051],\n",
      "        [0.8780],\n",
      "        [0.9052],\n",
      "        [0.4660],\n",
      "        [0.4846],\n",
      "        [0.8610],\n",
      "        [0.9024]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6957],\n",
      "        [0.4280],\n",
      "        [0.4237],\n",
      "        [0.4935],\n",
      "        [0.7115],\n",
      "        [0.5082],\n",
      "        [0.8323],\n",
      "        [0.5131],\n",
      "        [0.4452],\n",
      "        [0.4856]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 12, Loss: 0.4632528168814523\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4207],\n",
      "        [0.8265],\n",
      "        [0.5864],\n",
      "        [0.5412],\n",
      "        [0.7423],\n",
      "        [0.9029],\n",
      "        [0.8692],\n",
      "        [0.8497],\n",
      "        [0.6959],\n",
      "        [0.8149]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9163],\n",
      "        [0.4571],\n",
      "        [0.4983],\n",
      "        [0.4449],\n",
      "        [0.4676],\n",
      "        [0.6251],\n",
      "        [0.5773],\n",
      "        [0.5064],\n",
      "        [0.4738],\n",
      "        [0.4919]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3262],\n",
      "        [0.6547],\n",
      "        [0.8199],\n",
      "        [0.6046],\n",
      "        [0.5002],\n",
      "        [0.4032],\n",
      "        [0.4582],\n",
      "        [0.5268],\n",
      "        [0.9132],\n",
      "        [0.8888]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5944],\n",
      "        [0.4658],\n",
      "        [0.6787],\n",
      "        [0.7762],\n",
      "        [0.4176],\n",
      "        [0.4623],\n",
      "        [0.4186],\n",
      "        [0.4409],\n",
      "        [0.6756],\n",
      "        [0.7093]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9287],\n",
      "        [0.4401],\n",
      "        [0.4209],\n",
      "        [0.5363],\n",
      "        [0.6259],\n",
      "        [0.9029],\n",
      "        [0.9315],\n",
      "        [0.4674],\n",
      "        [0.4768],\n",
      "        [0.6804]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8648],\n",
      "        [0.4298],\n",
      "        [0.7213],\n",
      "        [0.8089],\n",
      "        [0.8809],\n",
      "        [0.9087],\n",
      "        [0.4505],\n",
      "        [0.4125],\n",
      "        [0.8983],\n",
      "        [0.9075]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6262],\n",
      "        [0.4355],\n",
      "        [0.4722],\n",
      "        [0.3989],\n",
      "        [0.7178],\n",
      "        [0.4575],\n",
      "        [0.8802],\n",
      "        [0.5489],\n",
      "        [0.4156],\n",
      "        [0.4463]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 13, Loss: 0.4438202253409794\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4446],\n",
      "        [0.8329],\n",
      "        [0.5805],\n",
      "        [0.5153],\n",
      "        [0.6856],\n",
      "        [0.8865],\n",
      "        [0.8659],\n",
      "        [0.8442],\n",
      "        [0.6914],\n",
      "        [0.8485]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9056],\n",
      "        [0.4550],\n",
      "        [0.4608],\n",
      "        [0.4386],\n",
      "        [0.4900],\n",
      "        [0.6835],\n",
      "        [0.6579],\n",
      "        [0.4517],\n",
      "        [0.4578],\n",
      "        [0.5648]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3924],\n",
      "        [0.5879],\n",
      "        [0.8864],\n",
      "        [0.6928],\n",
      "        [0.3656],\n",
      "        [0.4254],\n",
      "        [0.4847],\n",
      "        [0.5488],\n",
      "        [0.9137],\n",
      "        [0.8845]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5325],\n",
      "        [0.4950],\n",
      "        [0.7773],\n",
      "        [0.7989],\n",
      "        [0.4454],\n",
      "        [0.4561],\n",
      "        [0.5260],\n",
      "        [0.4579],\n",
      "        [0.6305],\n",
      "        [0.7376]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9319],\n",
      "        [0.4246],\n",
      "        [0.4607],\n",
      "        [0.5670],\n",
      "        [0.6317],\n",
      "        [0.9560],\n",
      "        [0.9221],\n",
      "        [0.4491],\n",
      "        [0.4541],\n",
      "        [0.6248]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8354],\n",
      "        [0.4083],\n",
      "        [0.7662],\n",
      "        [0.7885],\n",
      "        [0.9226],\n",
      "        [0.9433],\n",
      "        [0.4774],\n",
      "        [0.4181],\n",
      "        [0.9413],\n",
      "        [0.9340]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6262],\n",
      "        [0.4258],\n",
      "        [0.4118],\n",
      "        [0.4623],\n",
      "        [0.7676],\n",
      "        [0.3924],\n",
      "        [0.9354],\n",
      "        [0.5506],\n",
      "        [0.4426],\n",
      "        [0.5348]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 14, Loss: 0.4346253616469247\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4475],\n",
      "        [0.8611],\n",
      "        [0.5323],\n",
      "        [0.4456],\n",
      "        [0.6925],\n",
      "        [0.9400],\n",
      "        [0.8793],\n",
      "        [0.9007],\n",
      "        [0.6625],\n",
      "        [0.8509]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9514],\n",
      "        [0.3944],\n",
      "        [0.4189],\n",
      "        [0.4253],\n",
      "        [0.4367],\n",
      "        [0.6358],\n",
      "        [0.6450],\n",
      "        [0.5048],\n",
      "        [0.4676],\n",
      "        [0.5404]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3822],\n",
      "        [0.5997],\n",
      "        [0.8662],\n",
      "        [0.6780],\n",
      "        [0.4465],\n",
      "        [0.4209],\n",
      "        [0.4135],\n",
      "        [0.4280],\n",
      "        [0.8754],\n",
      "        [0.9538]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4626],\n",
      "        [0.4145],\n",
      "        [0.7633],\n",
      "        [0.8188],\n",
      "        [0.4477],\n",
      "        [0.3935],\n",
      "        [0.4177],\n",
      "        [0.4325],\n",
      "        [0.6780],\n",
      "        [0.7493]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9397],\n",
      "        [0.4691],\n",
      "        [0.4523],\n",
      "        [0.5182],\n",
      "        [0.6526],\n",
      "        [0.9240],\n",
      "        [0.9149],\n",
      "        [0.4271],\n",
      "        [0.4425],\n",
      "        [0.7036]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7998],\n",
      "        [0.3942],\n",
      "        [0.7675],\n",
      "        [0.8443],\n",
      "        [0.9304],\n",
      "        [0.9117],\n",
      "        [0.4784],\n",
      "        [0.4141],\n",
      "        [0.9476],\n",
      "        [0.9357]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5538],\n",
      "        [0.4011],\n",
      "        [0.4124],\n",
      "        [0.4761],\n",
      "        [0.7519],\n",
      "        [0.3486],\n",
      "        [0.9188],\n",
      "        [0.5034],\n",
      "        [0.3381],\n",
      "        [0.4858]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 15, Loss: 0.4248934430735452\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3905],\n",
      "        [0.9048],\n",
      "        [0.4676],\n",
      "        [0.4385],\n",
      "        [0.7002],\n",
      "        [0.9162],\n",
      "        [0.8771],\n",
      "        [0.8934],\n",
      "        [0.6747],\n",
      "        [0.8719]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9633],\n",
      "        [0.3856],\n",
      "        [0.4234],\n",
      "        [0.4697],\n",
      "        [0.4593],\n",
      "        [0.6203],\n",
      "        [0.6815],\n",
      "        [0.4792],\n",
      "        [0.4264],\n",
      "        [0.5628]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3488],\n",
      "        [0.5832],\n",
      "        [0.8858],\n",
      "        [0.7330],\n",
      "        [0.4196],\n",
      "        [0.3339],\n",
      "        [0.3901],\n",
      "        [0.5272],\n",
      "        [0.9221],\n",
      "        [0.9686]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4825],\n",
      "        [0.4581],\n",
      "        [0.7779],\n",
      "        [0.8453],\n",
      "        [0.3526],\n",
      "        [0.4626],\n",
      "        [0.4084],\n",
      "        [0.4373],\n",
      "        [0.6241],\n",
      "        [0.7401]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9463],\n",
      "        [0.3755],\n",
      "        [0.4711],\n",
      "        [0.5151],\n",
      "        [0.6841],\n",
      "        [0.9502],\n",
      "        [0.9519],\n",
      "        [0.3811],\n",
      "        [0.3905],\n",
      "        [0.7686]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8540],\n",
      "        [0.3568],\n",
      "        [0.7428],\n",
      "        [0.8857],\n",
      "        [0.9583],\n",
      "        [0.8984],\n",
      "        [0.4099],\n",
      "        [0.3882],\n",
      "        [0.9447],\n",
      "        [0.9059]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6628],\n",
      "        [0.4722],\n",
      "        [0.3570],\n",
      "        [0.4062],\n",
      "        [0.7146],\n",
      "        [0.4671],\n",
      "        [0.9301],\n",
      "        [0.5439],\n",
      "        [0.3668],\n",
      "        [0.5297]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 16, Loss: 0.399215395961489\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4104],\n",
      "        [0.8858],\n",
      "        [0.5211],\n",
      "        [0.4692],\n",
      "        [0.7405],\n",
      "        [0.9330],\n",
      "        [0.9053],\n",
      "        [0.8735],\n",
      "        [0.7401],\n",
      "        [0.8834]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9220],\n",
      "        [0.3841],\n",
      "        [0.4541],\n",
      "        [0.3294],\n",
      "        [0.4551],\n",
      "        [0.6138],\n",
      "        [0.6662],\n",
      "        [0.4659],\n",
      "        [0.4935],\n",
      "        [0.4811]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3464],\n",
      "        [0.6382],\n",
      "        [0.8638],\n",
      "        [0.6469],\n",
      "        [0.4214],\n",
      "        [0.3311],\n",
      "        [0.4272],\n",
      "        [0.5139],\n",
      "        [0.9479],\n",
      "        [0.9392]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4742],\n",
      "        [0.4142],\n",
      "        [0.7851],\n",
      "        [0.8523],\n",
      "        [0.3883],\n",
      "        [0.3949],\n",
      "        [0.4619],\n",
      "        [0.4124],\n",
      "        [0.6423],\n",
      "        [0.7472]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9691],\n",
      "        [0.5188],\n",
      "        [0.4418],\n",
      "        [0.5007],\n",
      "        [0.6966],\n",
      "        [0.9335],\n",
      "        [0.9651],\n",
      "        [0.4994],\n",
      "        [0.4397],\n",
      "        [0.7491]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8769],\n",
      "        [0.3634],\n",
      "        [0.8025],\n",
      "        [0.8077],\n",
      "        [0.9601],\n",
      "        [0.8345],\n",
      "        [0.4710],\n",
      "        [0.4365],\n",
      "        [0.9591],\n",
      "        [0.9441]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6652],\n",
      "        [0.4622],\n",
      "        [0.3968],\n",
      "        [0.3746],\n",
      "        [0.8287],\n",
      "        [0.3953],\n",
      "        [0.9348],\n",
      "        [0.6239],\n",
      "        [0.3379],\n",
      "        [0.4333]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 17, Loss: 0.40193850227764677\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3619],\n",
      "        [0.9220],\n",
      "        [0.4995],\n",
      "        [0.4172],\n",
      "        [0.7289],\n",
      "        [0.9656],\n",
      "        [0.9174],\n",
      "        [0.9208],\n",
      "        [0.7891],\n",
      "        [0.9133]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9544],\n",
      "        [0.3719],\n",
      "        [0.4515],\n",
      "        [0.3234],\n",
      "        [0.4938],\n",
      "        [0.7324],\n",
      "        [0.6609],\n",
      "        [0.4119],\n",
      "        [0.4688],\n",
      "        [0.5421]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3608],\n",
      "        [0.5837],\n",
      "        [0.9220],\n",
      "        [0.7012],\n",
      "        [0.4379],\n",
      "        [0.3552],\n",
      "        [0.3764],\n",
      "        [0.5100],\n",
      "        [0.9230],\n",
      "        [0.9585]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5274],\n",
      "        [0.3979],\n",
      "        [0.7866],\n",
      "        [0.8283],\n",
      "        [0.3530],\n",
      "        [0.3980],\n",
      "        [0.4054],\n",
      "        [0.4527],\n",
      "        [0.6823],\n",
      "        [0.7136]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9794],\n",
      "        [0.4817],\n",
      "        [0.3467],\n",
      "        [0.5025],\n",
      "        [0.6583],\n",
      "        [0.9581],\n",
      "        [0.9682],\n",
      "        [0.4246],\n",
      "        [0.3543],\n",
      "        [0.7175]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8148],\n",
      "        [0.3635],\n",
      "        [0.8269],\n",
      "        [0.9004],\n",
      "        [0.9183],\n",
      "        [0.9401],\n",
      "        [0.4283],\n",
      "        [0.4125],\n",
      "        [0.9446],\n",
      "        [0.9300]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6651],\n",
      "        [0.3456],\n",
      "        [0.4547],\n",
      "        [0.4696],\n",
      "        [0.8447],\n",
      "        [0.4695],\n",
      "        [0.9577],\n",
      "        [0.5871],\n",
      "        [0.3281],\n",
      "        [0.4535]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 18, Loss: 0.38882820308208466\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3492],\n",
      "        [0.8571],\n",
      "        [0.4999],\n",
      "        [0.3394],\n",
      "        [0.7165],\n",
      "        [0.9654],\n",
      "        [0.9457],\n",
      "        [0.9184],\n",
      "        [0.7290],\n",
      "        [0.9040]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9693],\n",
      "        [0.4265],\n",
      "        [0.3922],\n",
      "        [0.3534],\n",
      "        [0.4606],\n",
      "        [0.7065],\n",
      "        [0.6944],\n",
      "        [0.4119],\n",
      "        [0.4082],\n",
      "        [0.5535]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2807],\n",
      "        [0.6476],\n",
      "        [0.9243],\n",
      "        [0.6934],\n",
      "        [0.4193],\n",
      "        [0.3428],\n",
      "        [0.4132],\n",
      "        [0.5069],\n",
      "        [0.9576],\n",
      "        [0.9512]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4486],\n",
      "        [0.4085],\n",
      "        [0.7870],\n",
      "        [0.8646],\n",
      "        [0.3719],\n",
      "        [0.3704],\n",
      "        [0.3463],\n",
      "        [0.3698],\n",
      "        [0.6886],\n",
      "        [0.7470]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9576],\n",
      "        [0.3493],\n",
      "        [0.4317],\n",
      "        [0.5241],\n",
      "        [0.6474],\n",
      "        [0.9678],\n",
      "        [0.9737],\n",
      "        [0.4809],\n",
      "        [0.3866],\n",
      "        [0.7288]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9085],\n",
      "        [0.3334],\n",
      "        [0.8637],\n",
      "        [0.8426],\n",
      "        [0.9678],\n",
      "        [0.9602],\n",
      "        [0.4973],\n",
      "        [0.3260],\n",
      "        [0.9530],\n",
      "        [0.9140]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6153],\n",
      "        [0.3265],\n",
      "        [0.2789],\n",
      "        [0.3834],\n",
      "        [0.8378],\n",
      "        [0.3991],\n",
      "        [0.9436],\n",
      "        [0.5429],\n",
      "        [0.3143],\n",
      "        [0.4852]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 19, Loss: 0.37250909422125134\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3044],\n",
      "        [0.8979],\n",
      "        [0.4867],\n",
      "        [0.4254],\n",
      "        [0.8312],\n",
      "        [0.9659],\n",
      "        [0.9526],\n",
      "        [0.9415],\n",
      "        [0.7176],\n",
      "        [0.9264]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9514],\n",
      "        [0.2627],\n",
      "        [0.4556],\n",
      "        [0.3527],\n",
      "        [0.3996],\n",
      "        [0.6183],\n",
      "        [0.7661],\n",
      "        [0.4612],\n",
      "        [0.4392],\n",
      "        [0.4418]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2915],\n",
      "        [0.6035],\n",
      "        [0.9242],\n",
      "        [0.7124],\n",
      "        [0.3923],\n",
      "        [0.3772],\n",
      "        [0.4558],\n",
      "        [0.5279],\n",
      "        [0.9538],\n",
      "        [0.9825]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4697],\n",
      "        [0.3147],\n",
      "        [0.7812],\n",
      "        [0.9051],\n",
      "        [0.3020],\n",
      "        [0.3648],\n",
      "        [0.3832],\n",
      "        [0.4140],\n",
      "        [0.6375],\n",
      "        [0.7441]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9749],\n",
      "        [0.3829],\n",
      "        [0.4189],\n",
      "        [0.4857],\n",
      "        [0.6857],\n",
      "        [0.9808],\n",
      "        [0.9686],\n",
      "        [0.4589],\n",
      "        [0.3669],\n",
      "        [0.7476]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8638],\n",
      "        [0.3054],\n",
      "        [0.8520],\n",
      "        [0.9155],\n",
      "        [0.9622],\n",
      "        [0.9842],\n",
      "        [0.3764],\n",
      "        [0.3862],\n",
      "        [0.9786],\n",
      "        [0.9652]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6268],\n",
      "        [0.3825],\n",
      "        [0.3357],\n",
      "        [0.3490],\n",
      "        [0.8903],\n",
      "        [0.2935],\n",
      "        [0.9466],\n",
      "        [0.5561],\n",
      "        [0.2979],\n",
      "        [0.3346]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 20, Loss: 0.36973401265484945\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2425],\n",
      "        [0.9569],\n",
      "        [0.4582],\n",
      "        [0.4850],\n",
      "        [0.7662],\n",
      "        [0.9573],\n",
      "        [0.9296],\n",
      "        [0.9550],\n",
      "        [0.8101],\n",
      "        [0.9155]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9748],\n",
      "        [0.3557],\n",
      "        [0.3865],\n",
      "        [0.3717],\n",
      "        [0.4668],\n",
      "        [0.7283],\n",
      "        [0.7236],\n",
      "        [0.4346],\n",
      "        [0.3709],\n",
      "        [0.4312]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3178],\n",
      "        [0.6542],\n",
      "        [0.9252],\n",
      "        [0.7628],\n",
      "        [0.3644],\n",
      "        [0.3173],\n",
      "        [0.3342],\n",
      "        [0.4621],\n",
      "        [0.9704],\n",
      "        [0.9795]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4657],\n",
      "        [0.3770],\n",
      "        [0.7699],\n",
      "        [0.8875],\n",
      "        [0.3008],\n",
      "        [0.3552],\n",
      "        [0.4311],\n",
      "        [0.3942],\n",
      "        [0.7031],\n",
      "        [0.7265]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9796],\n",
      "        [0.4166],\n",
      "        [0.3339],\n",
      "        [0.4740],\n",
      "        [0.6647],\n",
      "        [0.9732],\n",
      "        [0.9738],\n",
      "        [0.3998],\n",
      "        [0.3190],\n",
      "        [0.7723]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9064],\n",
      "        [0.2815],\n",
      "        [0.8835],\n",
      "        [0.9311],\n",
      "        [0.9483],\n",
      "        [0.9750],\n",
      "        [0.4034],\n",
      "        [0.3203],\n",
      "        [0.9733],\n",
      "        [0.9765]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6107],\n",
      "        [0.3784],\n",
      "        [0.3150],\n",
      "        [0.3160],\n",
      "        [0.8504],\n",
      "        [0.3423],\n",
      "        [0.9496],\n",
      "        [0.6244],\n",
      "        [0.3003],\n",
      "        [0.4072]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 21, Loss: 0.3568189378295626\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3488],\n",
      "        [0.9381],\n",
      "        [0.4383],\n",
      "        [0.3956],\n",
      "        [0.7730],\n",
      "        [0.9762],\n",
      "        [0.9615],\n",
      "        [0.9531],\n",
      "        [0.7873],\n",
      "        [0.9514]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9845],\n",
      "        [0.2507],\n",
      "        [0.3761],\n",
      "        [0.2784],\n",
      "        [0.3795],\n",
      "        [0.7347],\n",
      "        [0.6989],\n",
      "        [0.3465],\n",
      "        [0.4449],\n",
      "        [0.4602]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2800],\n",
      "        [0.6461],\n",
      "        [0.9411],\n",
      "        [0.7150],\n",
      "        [0.3581],\n",
      "        [0.2611],\n",
      "        [0.4829],\n",
      "        [0.4821],\n",
      "        [0.9725],\n",
      "        [0.9865]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5096],\n",
      "        [0.3081],\n",
      "        [0.8135],\n",
      "        [0.8990],\n",
      "        [0.3565],\n",
      "        [0.3317],\n",
      "        [0.3991],\n",
      "        [0.3706],\n",
      "        [0.7532],\n",
      "        [0.7778]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9704],\n",
      "        [0.3887],\n",
      "        [0.3350],\n",
      "        [0.4741],\n",
      "        [0.6995],\n",
      "        [0.9848],\n",
      "        [0.9732],\n",
      "        [0.3586],\n",
      "        [0.4288],\n",
      "        [0.7490]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9281],\n",
      "        [0.2796],\n",
      "        [0.9110],\n",
      "        [0.9004],\n",
      "        [0.9758],\n",
      "        [0.9862],\n",
      "        [0.3962],\n",
      "        [0.3218],\n",
      "        [0.9682],\n",
      "        [0.9535]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6498],\n",
      "        [0.3236],\n",
      "        [0.2770],\n",
      "        [0.3545],\n",
      "        [0.8636],\n",
      "        [0.3200],\n",
      "        [0.9739],\n",
      "        [0.5533],\n",
      "        [0.2703],\n",
      "        [0.3528]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 22, Loss: 0.3449396469763347\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3236],\n",
      "        [0.9646],\n",
      "        [0.4549],\n",
      "        [0.3599],\n",
      "        [0.7624],\n",
      "        [0.9754],\n",
      "        [0.9441],\n",
      "        [0.9757],\n",
      "        [0.7806],\n",
      "        [0.9511]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9906],\n",
      "        [0.3915],\n",
      "        [0.3736],\n",
      "        [0.2642],\n",
      "        [0.4804],\n",
      "        [0.6253],\n",
      "        [0.6798],\n",
      "        [0.3821],\n",
      "        [0.4527],\n",
      "        [0.4435]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2610],\n",
      "        [0.6132],\n",
      "        [0.9507],\n",
      "        [0.7997],\n",
      "        [0.3436],\n",
      "        [0.2462],\n",
      "        [0.3391],\n",
      "        [0.5115],\n",
      "        [0.9540],\n",
      "        [0.9766]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3719],\n",
      "        [0.3243],\n",
      "        [0.8032],\n",
      "        [0.9011],\n",
      "        [0.2455],\n",
      "        [0.2502],\n",
      "        [0.3742],\n",
      "        [0.3764],\n",
      "        [0.7357],\n",
      "        [0.7887]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9805],\n",
      "        [0.4087],\n",
      "        [0.3424],\n",
      "        [0.4362],\n",
      "        [0.7330],\n",
      "        [0.9655],\n",
      "        [0.9781],\n",
      "        [0.3273],\n",
      "        [0.3217],\n",
      "        [0.7793]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8905],\n",
      "        [0.3580],\n",
      "        [0.8806],\n",
      "        [0.9322],\n",
      "        [0.9868],\n",
      "        [0.9882],\n",
      "        [0.4195],\n",
      "        [0.2596],\n",
      "        [0.9742],\n",
      "        [0.9706]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7082],\n",
      "        [0.3908],\n",
      "        [0.3009],\n",
      "        [0.3163],\n",
      "        [0.8890],\n",
      "        [0.3659],\n",
      "        [0.9640],\n",
      "        [0.5228],\n",
      "        [0.2463],\n",
      "        [0.3642]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 23, Loss: 0.33931734945092884\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3327],\n",
      "        [0.9628],\n",
      "        [0.5603],\n",
      "        [0.4218],\n",
      "        [0.8014],\n",
      "        [0.9883],\n",
      "        [0.9523],\n",
      "        [0.9652],\n",
      "        [0.7546],\n",
      "        [0.9336]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9867],\n",
      "        [0.3433],\n",
      "        [0.3533],\n",
      "        [0.2773],\n",
      "        [0.4054],\n",
      "        [0.6664],\n",
      "        [0.6715],\n",
      "        [0.3927],\n",
      "        [0.3560],\n",
      "        [0.4805]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2659],\n",
      "        [0.6586],\n",
      "        [0.9360],\n",
      "        [0.6501],\n",
      "        [0.3426],\n",
      "        [0.2195],\n",
      "        [0.3560],\n",
      "        [0.4012],\n",
      "        [0.9742],\n",
      "        [0.9872]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4780],\n",
      "        [0.3374],\n",
      "        [0.8210],\n",
      "        [0.8999],\n",
      "        [0.2879],\n",
      "        [0.3127],\n",
      "        [0.3704],\n",
      "        [0.3695],\n",
      "        [0.6741],\n",
      "        [0.7619]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9946],\n",
      "        [0.3243],\n",
      "        [0.4068],\n",
      "        [0.4444],\n",
      "        [0.7784],\n",
      "        [0.9903],\n",
      "        [0.9837],\n",
      "        [0.3642],\n",
      "        [0.3096],\n",
      "        [0.7930]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9448],\n",
      "        [0.2867],\n",
      "        [0.9352],\n",
      "        [0.9274],\n",
      "        [0.9803],\n",
      "        [0.9764],\n",
      "        [0.4720],\n",
      "        [0.2957],\n",
      "        [0.9890],\n",
      "        [0.9750]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6201],\n",
      "        [0.4404],\n",
      "        [0.2833],\n",
      "        [0.3354],\n",
      "        [0.9023],\n",
      "        [0.3054],\n",
      "        [0.9793],\n",
      "        [0.5762],\n",
      "        [0.2249],\n",
      "        [0.3248]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 24, Loss: 0.33575256381716045\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3214],\n",
      "        [0.9422],\n",
      "        [0.5516],\n",
      "        [0.4017],\n",
      "        [0.8622],\n",
      "        [0.9890],\n",
      "        [0.9693],\n",
      "        [0.9748],\n",
      "        [0.8701],\n",
      "        [0.9399]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9923],\n",
      "        [0.2441],\n",
      "        [0.3628],\n",
      "        [0.2786],\n",
      "        [0.3464],\n",
      "        [0.6959],\n",
      "        [0.7449],\n",
      "        [0.3959],\n",
      "        [0.4040],\n",
      "        [0.4788]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2402],\n",
      "        [0.6349],\n",
      "        [0.9754],\n",
      "        [0.7463],\n",
      "        [0.2565],\n",
      "        [0.2503],\n",
      "        [0.3442],\n",
      "        [0.4201],\n",
      "        [0.9841],\n",
      "        [0.9807]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3999],\n",
      "        [0.2704],\n",
      "        [0.8708],\n",
      "        [0.9155],\n",
      "        [0.3368],\n",
      "        [0.2979],\n",
      "        [0.3411],\n",
      "        [0.2628],\n",
      "        [0.7211],\n",
      "        [0.8016]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9945],\n",
      "        [0.3282],\n",
      "        [0.3413],\n",
      "        [0.4999],\n",
      "        [0.7542],\n",
      "        [0.9832],\n",
      "        [0.9933],\n",
      "        [0.4319],\n",
      "        [0.3780],\n",
      "        [0.8182]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9431],\n",
      "        [0.2608],\n",
      "        [0.8910],\n",
      "        [0.9184],\n",
      "        [0.9818],\n",
      "        [0.9941],\n",
      "        [0.4069],\n",
      "        [0.2810],\n",
      "        [0.9883],\n",
      "        [0.9753]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7501],\n",
      "        [0.2963],\n",
      "        [0.2822],\n",
      "        [0.3388],\n",
      "        [0.8949],\n",
      "        [0.2128],\n",
      "        [0.9861],\n",
      "        [0.6352],\n",
      "        [0.3535],\n",
      "        [0.2958]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 25, Loss: 0.3185161863054548\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2762],\n",
      "        [0.9658],\n",
      "        [0.5605],\n",
      "        [0.3575],\n",
      "        [0.8173],\n",
      "        [0.9929],\n",
      "        [0.9671],\n",
      "        [0.9761],\n",
      "        [0.8472],\n",
      "        [0.9616]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9908],\n",
      "        [0.3051],\n",
      "        [0.3141],\n",
      "        [0.2120],\n",
      "        [0.3659],\n",
      "        [0.6905],\n",
      "        [0.7470],\n",
      "        [0.3913],\n",
      "        [0.3736],\n",
      "        [0.4467]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2374],\n",
      "        [0.6564],\n",
      "        [0.9547],\n",
      "        [0.8218],\n",
      "        [0.3263],\n",
      "        [0.2276],\n",
      "        [0.4444],\n",
      "        [0.4986],\n",
      "        [0.9889],\n",
      "        [0.9926]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3870],\n",
      "        [0.2689],\n",
      "        [0.8563],\n",
      "        [0.8989],\n",
      "        [0.3009],\n",
      "        [0.2772],\n",
      "        [0.3379],\n",
      "        [0.2936],\n",
      "        [0.7517],\n",
      "        [0.8441]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9914],\n",
      "        [0.3140],\n",
      "        [0.2674],\n",
      "        [0.5015],\n",
      "        [0.7180],\n",
      "        [0.9703],\n",
      "        [0.9901],\n",
      "        [0.3521],\n",
      "        [0.3983],\n",
      "        [0.8257]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9541],\n",
      "        [0.2552],\n",
      "        [0.9198],\n",
      "        [0.9111],\n",
      "        [0.9769],\n",
      "        [0.9944],\n",
      "        [0.3313],\n",
      "        [0.3206],\n",
      "        [0.9881],\n",
      "        [0.9926]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6850],\n",
      "        [0.3145],\n",
      "        [0.2569],\n",
      "        [0.2381],\n",
      "        [0.8071],\n",
      "        [0.2926],\n",
      "        [0.9904],\n",
      "        [0.5891],\n",
      "        [0.2573],\n",
      "        [0.3639]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 26, Loss: 0.3072114565542766\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2402],\n",
      "        [0.9609],\n",
      "        [0.5399],\n",
      "        [0.3844],\n",
      "        [0.8127],\n",
      "        [0.9838],\n",
      "        [0.9799],\n",
      "        [0.9823],\n",
      "        [0.8337],\n",
      "        [0.9774]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9845],\n",
      "        [0.3192],\n",
      "        [0.3077],\n",
      "        [0.3141],\n",
      "        [0.3951],\n",
      "        [0.7943],\n",
      "        [0.6985],\n",
      "        [0.3575],\n",
      "        [0.4125],\n",
      "        [0.5103]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2231],\n",
      "        [0.6443],\n",
      "        [0.9689],\n",
      "        [0.8471],\n",
      "        [0.3398],\n",
      "        [0.2788],\n",
      "        [0.2690],\n",
      "        [0.5084],\n",
      "        [0.9778],\n",
      "        [0.9921]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4614],\n",
      "        [0.2831],\n",
      "        [0.8487],\n",
      "        [0.9514],\n",
      "        [0.3068],\n",
      "        [0.2584],\n",
      "        [0.3221],\n",
      "        [0.3634],\n",
      "        [0.6534],\n",
      "        [0.8697]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9934],\n",
      "        [0.3200],\n",
      "        [0.2746],\n",
      "        [0.4557],\n",
      "        [0.7935],\n",
      "        [0.9917],\n",
      "        [0.9930],\n",
      "        [0.3907],\n",
      "        [0.3254],\n",
      "        [0.7658]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9569],\n",
      "        [0.2974],\n",
      "        [0.8700],\n",
      "        [0.9440],\n",
      "        [0.9902],\n",
      "        [0.9953],\n",
      "        [0.4096],\n",
      "        [0.2995],\n",
      "        [0.9868],\n",
      "        [0.9872]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7043],\n",
      "        [0.3768],\n",
      "        [0.2062],\n",
      "        [0.3092],\n",
      "        [0.8728],\n",
      "        [0.2759],\n",
      "        [0.9905],\n",
      "        [0.6097],\n",
      "        [0.1660],\n",
      "        [0.4069]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 27, Loss: 0.3064021681036268\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2157],\n",
      "        [0.9597],\n",
      "        [0.5688],\n",
      "        [0.3568],\n",
      "        [0.8336],\n",
      "        [0.9768],\n",
      "        [0.9855],\n",
      "        [0.9819],\n",
      "        [0.8844],\n",
      "        [0.9787]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9861],\n",
      "        [0.2637],\n",
      "        [0.3376],\n",
      "        [0.2409],\n",
      "        [0.4045],\n",
      "        [0.7579],\n",
      "        [0.7070],\n",
      "        [0.3011],\n",
      "        [0.3045],\n",
      "        [0.5165]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2648],\n",
      "        [0.5607],\n",
      "        [0.9576],\n",
      "        [0.8323],\n",
      "        [0.3497],\n",
      "        [0.2457],\n",
      "        [0.3040],\n",
      "        [0.4748],\n",
      "        [0.9929],\n",
      "        [0.9942]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4568],\n",
      "        [0.2673],\n",
      "        [0.8825],\n",
      "        [0.9717],\n",
      "        [0.3258],\n",
      "        [0.3618],\n",
      "        [0.3661],\n",
      "        [0.3474],\n",
      "        [0.8008],\n",
      "        [0.8356]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9976],\n",
      "        [0.3760],\n",
      "        [0.3304],\n",
      "        [0.5085],\n",
      "        [0.6886],\n",
      "        [0.9911],\n",
      "        [0.9959],\n",
      "        [0.3906],\n",
      "        [0.2542],\n",
      "        [0.7042]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9611],\n",
      "        [0.2452],\n",
      "        [0.9058],\n",
      "        [0.9712],\n",
      "        [0.9937],\n",
      "        [0.9825],\n",
      "        [0.3817],\n",
      "        [0.2860],\n",
      "        [0.9951],\n",
      "        [0.9843]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7117],\n",
      "        [0.2701],\n",
      "        [0.1803],\n",
      "        [0.3365],\n",
      "        [0.9430],\n",
      "        [0.3700],\n",
      "        [0.9911],\n",
      "        [0.6055],\n",
      "        [0.2354],\n",
      "        [0.3484]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 28, Loss: 0.29980813392571043\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2034],\n",
      "        [0.9724],\n",
      "        [0.4406],\n",
      "        [0.3782],\n",
      "        [0.8690],\n",
      "        [0.9875],\n",
      "        [0.9838],\n",
      "        [0.9907],\n",
      "        [0.8649],\n",
      "        [0.9863]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9957],\n",
      "        [0.2462],\n",
      "        [0.2775],\n",
      "        [0.2952],\n",
      "        [0.4533],\n",
      "        [0.7571],\n",
      "        [0.6930],\n",
      "        [0.3814],\n",
      "        [0.3633],\n",
      "        [0.4471]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2090],\n",
      "        [0.6148],\n",
      "        [0.9549],\n",
      "        [0.7569],\n",
      "        [0.3655],\n",
      "        [0.1771],\n",
      "        [0.2752],\n",
      "        [0.4896],\n",
      "        [0.9874],\n",
      "        [0.9977]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5030],\n",
      "        [0.2527],\n",
      "        [0.8872],\n",
      "        [0.9647],\n",
      "        [0.2836],\n",
      "        [0.3178],\n",
      "        [0.4228],\n",
      "        [0.4125],\n",
      "        [0.7676],\n",
      "        [0.8545]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9922],\n",
      "        [0.3168],\n",
      "        [0.4064],\n",
      "        [0.5457],\n",
      "        [0.7737],\n",
      "        [0.9908],\n",
      "        [0.9943],\n",
      "        [0.3637],\n",
      "        [0.2634],\n",
      "        [0.8398]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9751],\n",
      "        [0.2130],\n",
      "        [0.8915],\n",
      "        [0.8993],\n",
      "        [0.9894],\n",
      "        [0.9966],\n",
      "        [0.2723],\n",
      "        [0.3671],\n",
      "        [0.9888],\n",
      "        [0.9930]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6766],\n",
      "        [0.2657],\n",
      "        [0.2534],\n",
      "        [0.2277],\n",
      "        [0.9446],\n",
      "        [0.2817],\n",
      "        [0.9867],\n",
      "        [0.6124],\n",
      "        [0.1960],\n",
      "        [0.3506]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 29, Loss: 0.30902117277894703\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2092],\n",
      "        [0.9828],\n",
      "        [0.4577],\n",
      "        [0.3290],\n",
      "        [0.8292],\n",
      "        [0.9966],\n",
      "        [0.9813],\n",
      "        [0.9834],\n",
      "        [0.9081],\n",
      "        [0.9872]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9910],\n",
      "        [0.2411],\n",
      "        [0.3007],\n",
      "        [0.2977],\n",
      "        [0.3907],\n",
      "        [0.7431],\n",
      "        [0.6482],\n",
      "        [0.3673],\n",
      "        [0.3336],\n",
      "        [0.4678]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2348],\n",
      "        [0.7009],\n",
      "        [0.9623],\n",
      "        [0.8490],\n",
      "        [0.3355],\n",
      "        [0.1828],\n",
      "        [0.2955],\n",
      "        [0.4438],\n",
      "        [0.9769],\n",
      "        [0.9957]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4181],\n",
      "        [0.2688],\n",
      "        [0.9236],\n",
      "        [0.9690],\n",
      "        [0.2558],\n",
      "        [0.2085],\n",
      "        [0.3725],\n",
      "        [0.3243],\n",
      "        [0.7181],\n",
      "        [0.8448]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9982],\n",
      "        [0.3139],\n",
      "        [0.3469],\n",
      "        [0.3361],\n",
      "        [0.7682],\n",
      "        [0.9809],\n",
      "        [0.9941],\n",
      "        [0.4373],\n",
      "        [0.3395],\n",
      "        [0.8181]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9798],\n",
      "        [0.2806],\n",
      "        [0.8793],\n",
      "        [0.9366],\n",
      "        [0.9976],\n",
      "        [0.9959],\n",
      "        [0.3811],\n",
      "        [0.2497],\n",
      "        [0.9957],\n",
      "        [0.9920]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7677],\n",
      "        [0.2892],\n",
      "        [0.2415],\n",
      "        [0.2620],\n",
      "        [0.9375],\n",
      "        [0.1955],\n",
      "        [0.9923],\n",
      "        [0.5813],\n",
      "        [0.1697],\n",
      "        [0.3469]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 30, Loss: 0.3115409016609192\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2198],\n",
      "        [0.9797],\n",
      "        [0.5223],\n",
      "        [0.3838],\n",
      "        [0.8392],\n",
      "        [0.9963],\n",
      "        [0.9873],\n",
      "        [0.9766],\n",
      "        [0.8914],\n",
      "        [0.9833]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9787],\n",
      "        [0.2661],\n",
      "        [0.3750],\n",
      "        [0.2676],\n",
      "        [0.3070],\n",
      "        [0.8193],\n",
      "        [0.6665],\n",
      "        [0.3308],\n",
      "        [0.3537],\n",
      "        [0.4225]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2077],\n",
      "        [0.6743],\n",
      "        [0.9830],\n",
      "        [0.8000],\n",
      "        [0.3554],\n",
      "        [0.1797],\n",
      "        [0.3369],\n",
      "        [0.5308],\n",
      "        [0.9904],\n",
      "        [0.9951]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.5356],\n",
      "        [0.2594],\n",
      "        [0.8694],\n",
      "        [0.9468],\n",
      "        [0.2045],\n",
      "        [0.3060],\n",
      "        [0.3216],\n",
      "        [0.3722],\n",
      "        [0.7547],\n",
      "        [0.8729]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9979],\n",
      "        [0.2972],\n",
      "        [0.4264],\n",
      "        [0.4510],\n",
      "        [0.7764],\n",
      "        [0.9904],\n",
      "        [0.9975],\n",
      "        [0.3454],\n",
      "        [0.2659],\n",
      "        [0.9031]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9808],\n",
      "        [0.2037],\n",
      "        [0.9389],\n",
      "        [0.9662],\n",
      "        [0.9909],\n",
      "        [0.9948],\n",
      "        [0.3166],\n",
      "        [0.2261],\n",
      "        [0.9979],\n",
      "        [0.9929]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6895],\n",
      "        [0.3545],\n",
      "        [0.1874],\n",
      "        [0.2051],\n",
      "        [0.9337],\n",
      "        [0.3543],\n",
      "        [0.9931],\n",
      "        [0.6645],\n",
      "        [0.2450],\n",
      "        [0.4982]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 31, Loss: 0.29616778982537134\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3551],\n",
      "        [0.9863],\n",
      "        [0.5040],\n",
      "        [0.3576],\n",
      "        [0.8509],\n",
      "        [0.9820],\n",
      "        [0.9890],\n",
      "        [0.9930],\n",
      "        [0.8752],\n",
      "        [0.9887]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9980],\n",
      "        [0.1783],\n",
      "        [0.3462],\n",
      "        [0.2903],\n",
      "        [0.2785],\n",
      "        [0.7234],\n",
      "        [0.7730],\n",
      "        [0.3644],\n",
      "        [0.3487],\n",
      "        [0.4986]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2273],\n",
      "        [0.7035],\n",
      "        [0.9764],\n",
      "        [0.8127],\n",
      "        [0.2860],\n",
      "        [0.2069],\n",
      "        [0.2352],\n",
      "        [0.4688],\n",
      "        [0.9932],\n",
      "        [0.9960]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4617],\n",
      "        [0.2794],\n",
      "        [0.9298],\n",
      "        [0.9706],\n",
      "        [0.1871],\n",
      "        [0.2397],\n",
      "        [0.3803],\n",
      "        [0.3514],\n",
      "        [0.8164],\n",
      "        [0.8526]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9953],\n",
      "        [0.3416],\n",
      "        [0.2984],\n",
      "        [0.4610],\n",
      "        [0.7783],\n",
      "        [0.9940],\n",
      "        [0.9980],\n",
      "        [0.4117],\n",
      "        [0.2218],\n",
      "        [0.8703]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9724],\n",
      "        [0.2378],\n",
      "        [0.9518],\n",
      "        [0.9749],\n",
      "        [0.9914],\n",
      "        [0.9983],\n",
      "        [0.3137],\n",
      "        [0.2248],\n",
      "        [0.9909],\n",
      "        [0.9944]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7949],\n",
      "        [0.3858],\n",
      "        [0.2282],\n",
      "        [0.2133],\n",
      "        [0.9357],\n",
      "        [0.3394],\n",
      "        [0.9942],\n",
      "        [0.6417],\n",
      "        [0.1749],\n",
      "        [0.3539]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 32, Loss: 0.2823054258312498\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3139],\n",
      "        [0.9903],\n",
      "        [0.4682],\n",
      "        [0.3660],\n",
      "        [0.8644],\n",
      "        [0.9933],\n",
      "        [0.9873],\n",
      "        [0.9793],\n",
      "        [0.8680],\n",
      "        [0.9924]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9982],\n",
      "        [0.2796],\n",
      "        [0.3575],\n",
      "        [0.2614],\n",
      "        [0.3344],\n",
      "        [0.8237],\n",
      "        [0.7835],\n",
      "        [0.2382],\n",
      "        [0.3108],\n",
      "        [0.5882]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2070],\n",
      "        [0.7412],\n",
      "        [0.9762],\n",
      "        [0.8710],\n",
      "        [0.2294],\n",
      "        [0.1934],\n",
      "        [0.3183],\n",
      "        [0.5166],\n",
      "        [0.9957],\n",
      "        [0.9980]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4704],\n",
      "        [0.2145],\n",
      "        [0.9342],\n",
      "        [0.9604],\n",
      "        [0.2150],\n",
      "        [0.2158],\n",
      "        [0.3744],\n",
      "        [0.2857],\n",
      "        [0.7664],\n",
      "        [0.8513]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9985],\n",
      "        [0.2362],\n",
      "        [0.2925],\n",
      "        [0.4880],\n",
      "        [0.8029],\n",
      "        [0.9964],\n",
      "        [0.9924],\n",
      "        [0.2868],\n",
      "        [0.2230],\n",
      "        [0.9167]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9816],\n",
      "        [0.1886],\n",
      "        [0.9629],\n",
      "        [0.9760],\n",
      "        [0.9807],\n",
      "        [0.9982],\n",
      "        [0.3627],\n",
      "        [0.2785],\n",
      "        [0.9918],\n",
      "        [0.9909]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7112],\n",
      "        [0.2202],\n",
      "        [0.1983],\n",
      "        [0.1784],\n",
      "        [0.9277],\n",
      "        [0.2811],\n",
      "        [0.9976],\n",
      "        [0.6784],\n",
      "        [0.1659],\n",
      "        [0.3436]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 33, Loss: 0.27435252389737536\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2630],\n",
      "        [0.9751],\n",
      "        [0.5651],\n",
      "        [0.3302],\n",
      "        [0.8782],\n",
      "        [0.9957],\n",
      "        [0.9927],\n",
      "        [0.9930],\n",
      "        [0.8798],\n",
      "        [0.9764]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9992],\n",
      "        [0.2448],\n",
      "        [0.3597],\n",
      "        [0.3364],\n",
      "        [0.3297],\n",
      "        [0.7737],\n",
      "        [0.8358],\n",
      "        [0.2878],\n",
      "        [0.3357],\n",
      "        [0.5821]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.1722],\n",
      "        [0.6300],\n",
      "        [0.9906],\n",
      "        [0.8465],\n",
      "        [0.2652],\n",
      "        [0.1807],\n",
      "        [0.2699],\n",
      "        [0.4793],\n",
      "        [0.9971],\n",
      "        [0.9937]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.3245],\n",
      "        [0.2981],\n",
      "        [0.9351],\n",
      "        [0.9775],\n",
      "        [0.1795],\n",
      "        [0.3451],\n",
      "        [0.2945],\n",
      "        [0.2259],\n",
      "        [0.8155],\n",
      "        [0.8516]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9991],\n",
      "        [0.3320],\n",
      "        [0.2436],\n",
      "        [0.4546],\n",
      "        [0.7040],\n",
      "        [0.9948],\n",
      "        [0.9989],\n",
      "        [0.3590],\n",
      "        [0.3026],\n",
      "        [0.9034]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9873],\n",
      "        [0.1916],\n",
      "        [0.9553],\n",
      "        [0.9647],\n",
      "        [0.9957],\n",
      "        [0.9988],\n",
      "        [0.3635],\n",
      "        [0.2411],\n",
      "        [0.9981],\n",
      "        [0.9962]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7416],\n",
      "        [0.2576],\n",
      "        [0.1843],\n",
      "        [0.2417],\n",
      "        [0.9563],\n",
      "        [0.2514],\n",
      "        [0.9886],\n",
      "        [0.6681],\n",
      "        [0.1776],\n",
      "        [0.2641]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 34, Loss: 0.2780741346733911\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.1872],\n",
      "        [0.9813],\n",
      "        [0.4507],\n",
      "        [0.3405],\n",
      "        [0.9036],\n",
      "        [0.9970],\n",
      "        [0.9959],\n",
      "        [0.9855],\n",
      "        [0.9291],\n",
      "        [0.9839]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9971],\n",
      "        [0.2207],\n",
      "        [0.3222],\n",
      "        [0.2487],\n",
      "        [0.3864],\n",
      "        [0.7292],\n",
      "        [0.8482],\n",
      "        [0.2645],\n",
      "        [0.3205],\n",
      "        [0.4844]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.1682],\n",
      "        [0.6602],\n",
      "        [0.9785],\n",
      "        [0.8546],\n",
      "        [0.2985],\n",
      "        [0.1710],\n",
      "        [0.3441],\n",
      "        [0.4970],\n",
      "        [0.9958],\n",
      "        [0.9928]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4180],\n",
      "        [0.1879],\n",
      "        [0.9093],\n",
      "        [0.9694],\n",
      "        [0.1660],\n",
      "        [0.3336],\n",
      "        [0.3947],\n",
      "        [0.1462],\n",
      "        [0.7275],\n",
      "        [0.8682]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9996],\n",
      "        [0.2551],\n",
      "        [0.2548],\n",
      "        [0.4208],\n",
      "        [0.8385],\n",
      "        [0.9978],\n",
      "        [0.9976],\n",
      "        [0.2332],\n",
      "        [0.2478],\n",
      "        [0.8578]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9844],\n",
      "        [0.1825],\n",
      "        [0.9612],\n",
      "        [0.9850],\n",
      "        [0.9863],\n",
      "        [0.9990],\n",
      "        [0.3325],\n",
      "        [0.1419],\n",
      "        [0.9983],\n",
      "        [0.9868]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7695],\n",
      "        [0.2413],\n",
      "        [0.1658],\n",
      "        [0.1886],\n",
      "        [0.9441],\n",
      "        [0.2212],\n",
      "        [0.9962],\n",
      "        [0.6219],\n",
      "        [0.1683],\n",
      "        [0.4332]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 35, Loss: 0.28121728130749296\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.1850],\n",
      "        [0.9783],\n",
      "        [0.4329],\n",
      "        [0.4380],\n",
      "        [0.8740],\n",
      "        [0.9889],\n",
      "        [0.9878],\n",
      "        [0.9933],\n",
      "        [0.9207],\n",
      "        [0.9872]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9988],\n",
      "        [0.1838],\n",
      "        [0.2091],\n",
      "        [0.1742],\n",
      "        [0.2808],\n",
      "        [0.7540],\n",
      "        [0.8032],\n",
      "        [0.2255],\n",
      "        [0.3550],\n",
      "        [0.4584]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.1303],\n",
      "        [0.7207],\n",
      "        [0.9802],\n",
      "        [0.8124],\n",
      "        [0.3218],\n",
      "        [0.1970],\n",
      "        [0.3666],\n",
      "        [0.4743],\n",
      "        [0.9927],\n",
      "        [0.9984]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4471],\n",
      "        [0.1978],\n",
      "        [0.9278],\n",
      "        [0.9733],\n",
      "        [0.2038],\n",
      "        [0.1855],\n",
      "        [0.3063],\n",
      "        [0.2524],\n",
      "        [0.7649],\n",
      "        [0.8882]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9937],\n",
      "        [0.2460],\n",
      "        [0.2781],\n",
      "        [0.3936],\n",
      "        [0.8289],\n",
      "        [0.9984],\n",
      "        [0.9987],\n",
      "        [0.2820],\n",
      "        [0.2316],\n",
      "        [0.8877]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9890],\n",
      "        [0.1825],\n",
      "        [0.9522],\n",
      "        [0.9599],\n",
      "        [0.9949],\n",
      "        [0.9917],\n",
      "        [0.3237],\n",
      "        [0.2931],\n",
      "        [0.9959],\n",
      "        [0.9958]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6736],\n",
      "        [0.2670],\n",
      "        [0.2099],\n",
      "        [0.1805],\n",
      "        [0.9522],\n",
      "        [0.2509],\n",
      "        [0.9946],\n",
      "        [0.5712],\n",
      "        [0.1290],\n",
      "        [0.2861]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 36, Loss: 0.2748631664684841\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2391],\n",
      "        [0.9909],\n",
      "        [0.4677],\n",
      "        [0.3238],\n",
      "        [0.9213],\n",
      "        [0.9961],\n",
      "        [0.9897],\n",
      "        [0.9837],\n",
      "        [0.8973],\n",
      "        [0.9923]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9993],\n",
      "        [0.2192],\n",
      "        [0.3455],\n",
      "        [0.2699],\n",
      "        [0.3267],\n",
      "        [0.8261],\n",
      "        [0.8296],\n",
      "        [0.3115],\n",
      "        [0.3691],\n",
      "        [0.4717]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.1103],\n",
      "        [0.7242],\n",
      "        [0.9886],\n",
      "        [0.8233],\n",
      "        [0.2168],\n",
      "        [0.1398],\n",
      "        [0.2665],\n",
      "        [0.6126],\n",
      "        [0.9981],\n",
      "        [0.9981]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4287],\n",
      "        [0.2619],\n",
      "        [0.9578],\n",
      "        [0.9757],\n",
      "        [0.2080],\n",
      "        [0.2211],\n",
      "        [0.3138],\n",
      "        [0.2789],\n",
      "        [0.7756],\n",
      "        [0.9072]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9953],\n",
      "        [0.3167],\n",
      "        [0.2360],\n",
      "        [0.4496],\n",
      "        [0.7908],\n",
      "        [0.9971],\n",
      "        [0.9958],\n",
      "        [0.3438],\n",
      "        [0.2106],\n",
      "        [0.8358]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9841],\n",
      "        [0.1817],\n",
      "        [0.9527],\n",
      "        [0.9869],\n",
      "        [0.9987],\n",
      "        [0.9992],\n",
      "        [0.3548],\n",
      "        [0.1415],\n",
      "        [0.9965],\n",
      "        [0.9918]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7977],\n",
      "        [0.2310],\n",
      "        [0.2030],\n",
      "        [0.2385],\n",
      "        [0.9784],\n",
      "        [0.2421],\n",
      "        [0.9961],\n",
      "        [0.6927],\n",
      "        [0.1443],\n",
      "        [0.3156]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 37, Loss: 0.26586345051016125\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2083],\n",
      "        [0.9745],\n",
      "        [0.5296],\n",
      "        [0.2732],\n",
      "        [0.9511],\n",
      "        [0.9960],\n",
      "        [0.9934],\n",
      "        [0.9969],\n",
      "        [0.9031],\n",
      "        [0.9897]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9994],\n",
      "        [0.2040],\n",
      "        [0.2639],\n",
      "        [0.1323],\n",
      "        [0.3356],\n",
      "        [0.7094],\n",
      "        [0.8416],\n",
      "        [0.2485],\n",
      "        [0.3622],\n",
      "        [0.4405]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.2717],\n",
      "        [0.7573],\n",
      "        [0.9909],\n",
      "        [0.8479],\n",
      "        [0.2356],\n",
      "        [0.1585],\n",
      "        [0.2462],\n",
      "        [0.4438],\n",
      "        [0.9931],\n",
      "        [0.9992]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4765],\n",
      "        [0.2663],\n",
      "        [0.9141],\n",
      "        [0.9837],\n",
      "        [0.2327],\n",
      "        [0.2549],\n",
      "        [0.3987],\n",
      "        [0.2649],\n",
      "        [0.8035],\n",
      "        [0.9122]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9969],\n",
      "        [0.1896],\n",
      "        [0.1921],\n",
      "        [0.3748],\n",
      "        [0.7965],\n",
      "        [0.9982],\n",
      "        [0.9987],\n",
      "        [0.3305],\n",
      "        [0.1820],\n",
      "        [0.8613]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9809],\n",
      "        [0.2647],\n",
      "        [0.9606],\n",
      "        [0.9785],\n",
      "        [0.9990],\n",
      "        [0.9977],\n",
      "        [0.4256],\n",
      "        [0.2295],\n",
      "        [0.9946],\n",
      "        [0.9962]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7449],\n",
      "        [0.2846],\n",
      "        [0.1885],\n",
      "        [0.2242],\n",
      "        [0.9701],\n",
      "        [0.2331],\n",
      "        [0.9959],\n",
      "        [0.6376],\n",
      "        [0.1322],\n",
      "        [0.3108]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 38, Loss: 0.2696874865463802\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.1490],\n",
      "        [0.9922],\n",
      "        [0.4363],\n",
      "        [0.3314],\n",
      "        [0.9407],\n",
      "        [0.9984],\n",
      "        [0.9951],\n",
      "        [0.9920],\n",
      "        [0.9166],\n",
      "        [0.9857]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9995],\n",
      "        [0.1614],\n",
      "        [0.3417],\n",
      "        [0.1557],\n",
      "        [0.3036],\n",
      "        [0.7444],\n",
      "        [0.7760],\n",
      "        [0.2572],\n",
      "        [0.3021],\n",
      "        [0.4554]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.1691],\n",
      "        [0.7928],\n",
      "        [0.9888],\n",
      "        [0.8393],\n",
      "        [0.2852],\n",
      "        [0.1423],\n",
      "        [0.2892],\n",
      "        [0.3913],\n",
      "        [0.9950],\n",
      "        [0.9989]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4142],\n",
      "        [0.2164],\n",
      "        [0.9549],\n",
      "        [0.9860],\n",
      "        [0.1860],\n",
      "        [0.3374],\n",
      "        [0.3495],\n",
      "        [0.2608],\n",
      "        [0.7935],\n",
      "        [0.8759]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9976],\n",
      "        [0.2581],\n",
      "        [0.3165],\n",
      "        [0.4204],\n",
      "        [0.8197],\n",
      "        [0.9991],\n",
      "        [0.9989],\n",
      "        [0.2454],\n",
      "        [0.2452],\n",
      "        [0.9234]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9871],\n",
      "        [0.2078],\n",
      "        [0.9783],\n",
      "        [0.9849],\n",
      "        [0.9952],\n",
      "        [0.9987],\n",
      "        [0.3584],\n",
      "        [0.1623],\n",
      "        [0.9984],\n",
      "        [0.9974]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.8144],\n",
      "        [0.2230],\n",
      "        [0.1854],\n",
      "        [0.2257],\n",
      "        [0.9706],\n",
      "        [0.3144],\n",
      "        [0.9976],\n",
      "        [0.6977],\n",
      "        [0.1422],\n",
      "        [0.2440]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 39, Loss: 0.26511635737759726\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.1405],\n",
      "        [0.9918],\n",
      "        [0.6004],\n",
      "        [0.3010],\n",
      "        [0.9339],\n",
      "        [0.9981],\n",
      "        [0.9915],\n",
      "        [0.9954],\n",
      "        [0.8894],\n",
      "        [0.9948]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9996],\n",
      "        [0.2383],\n",
      "        [0.3146],\n",
      "        [0.1875],\n",
      "        [0.2973],\n",
      "        [0.7566],\n",
      "        [0.8205],\n",
      "        [0.3698],\n",
      "        [0.3002],\n",
      "        [0.4721]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.1373],\n",
      "        [0.8516],\n",
      "        [0.9850],\n",
      "        [0.8967],\n",
      "        [0.3302],\n",
      "        [0.1137],\n",
      "        [0.2856],\n",
      "        [0.6021],\n",
      "        [0.9985],\n",
      "        [0.9995]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4783],\n",
      "        [0.2271],\n",
      "        [0.9335],\n",
      "        [0.9752],\n",
      "        [0.1907],\n",
      "        [0.2997],\n",
      "        [0.3169],\n",
      "        [0.2489],\n",
      "        [0.8547],\n",
      "        [0.9338]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9993],\n",
      "        [0.2755],\n",
      "        [0.2280],\n",
      "        [0.4425],\n",
      "        [0.8598],\n",
      "        [0.9995],\n",
      "        [0.9993],\n",
      "        [0.3032],\n",
      "        [0.2606],\n",
      "        [0.8704]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9875],\n",
      "        [0.2159],\n",
      "        [0.9655],\n",
      "        [0.9878],\n",
      "        [0.9977],\n",
      "        [0.9976],\n",
      "        [0.3043],\n",
      "        [0.1712],\n",
      "        [0.9986],\n",
      "        [0.9969]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7911],\n",
      "        [0.1945],\n",
      "        [0.1466],\n",
      "        [0.3365],\n",
      "        [0.9397],\n",
      "        [0.2514],\n",
      "        [0.9968],\n",
      "        [0.6524],\n",
      "        [0.1879],\n",
      "        [0.3882]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 40, Loss: 0.2632259503006935\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.1829],\n",
      "        [0.9962],\n",
      "        [0.5281],\n",
      "        [0.2959],\n",
      "        [0.9289],\n",
      "        [0.9975],\n",
      "        [0.9973],\n",
      "        [0.9961],\n",
      "        [0.8965],\n",
      "        [0.9955]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9994],\n",
      "        [0.2430],\n",
      "        [0.3466],\n",
      "        [0.2183],\n",
      "        [0.3052],\n",
      "        [0.8566],\n",
      "        [0.8283],\n",
      "        [0.3115],\n",
      "        [0.3716],\n",
      "        [0.5297]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.1514],\n",
      "        [0.8109],\n",
      "        [0.9803],\n",
      "        [0.8714],\n",
      "        [0.1696],\n",
      "        [0.1344],\n",
      "        [0.3043],\n",
      "        [0.5186],\n",
      "        [0.9975],\n",
      "        [0.9999]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4042],\n",
      "        [0.1951],\n",
      "        [0.9669],\n",
      "        [0.9862],\n",
      "        [0.2034],\n",
      "        [0.2440],\n",
      "        [0.4426],\n",
      "        [0.2675],\n",
      "        [0.7778],\n",
      "        [0.9189]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9998],\n",
      "        [0.3448],\n",
      "        [0.2661],\n",
      "        [0.5008],\n",
      "        [0.8460],\n",
      "        [0.9923],\n",
      "        [0.9996],\n",
      "        [0.2463],\n",
      "        [0.3786],\n",
      "        [0.9208]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9904],\n",
      "        [0.1697],\n",
      "        [0.9715],\n",
      "        [0.9896],\n",
      "        [0.9983],\n",
      "        [0.9988],\n",
      "        [0.3509],\n",
      "        [0.2482],\n",
      "        [0.9978],\n",
      "        [0.9973]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.6873],\n",
      "        [0.2108],\n",
      "        [0.2926],\n",
      "        [0.2405],\n",
      "        [0.9775],\n",
      "        [0.2520],\n",
      "        [0.9991],\n",
      "        [0.5911],\n",
      "        [0.1765],\n",
      "        [0.3643]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 41, Loss: 0.2688857338258198\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.1741],\n",
      "        [0.9918],\n",
      "        [0.4293],\n",
      "        [0.3319],\n",
      "        [0.9420],\n",
      "        [0.9975],\n",
      "        [0.9967],\n",
      "        [0.9976],\n",
      "        [0.9520],\n",
      "        [0.9803]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 0., 1., 1., 1., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9990],\n",
      "        [0.2127],\n",
      "        [0.3202],\n",
      "        [0.3121],\n",
      "        [0.3543],\n",
      "        [0.8397],\n",
      "        [0.7936],\n",
      "        [0.3128],\n",
      "        [0.3646],\n",
      "        [0.4733]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 0., 0., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.1545],\n",
      "        [0.7471],\n",
      "        [0.9939],\n",
      "        [0.9256],\n",
      "        [0.3424],\n",
      "        [0.2786],\n",
      "        [0.2499],\n",
      "        [0.4272],\n",
      "        [0.9990],\n",
      "        [0.9992]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 1., 1., 1., 0., 0., 0., 1., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.4665],\n",
      "        [0.2062],\n",
      "        [0.9626],\n",
      "        [0.9794],\n",
      "        [0.1857],\n",
      "        [0.2950],\n",
      "        [0.3132],\n",
      "        [0.2004],\n",
      "        [0.8451],\n",
      "        [0.8907]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([0., 0., 1., 1., 1., 0., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9995],\n",
      "        [0.2211],\n",
      "        [0.2521],\n",
      "        [0.4083],\n",
      "        [0.8556],\n",
      "        [0.9986],\n",
      "        [0.9991],\n",
      "        [0.2981],\n",
      "        [0.2493],\n",
      "        [0.9208]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 0., 1., 1., 1., 1., 0., 0., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.9824],\n",
      "        [0.1709],\n",
      "        [0.9590],\n",
      "        [0.9851],\n",
      "        [0.9991],\n",
      "        [0.9990],\n",
      "        [0.3080],\n",
      "        [0.2801],\n",
      "        [0.9944],\n",
      "        [0.9977]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 0., 1., 1., 1., 1., 0., 0., 1., 1.])\u001b[0m\n",
      "\u001b[34my_pred (torch.Size([10, 1])):\u001b[0m\n",
      "\u001b[34mtensor([[0.7346],\n",
      "        [0.3182],\n",
      "        [0.2350],\n",
      "        [0.2907],\n",
      "        [0.9588],\n",
      "        [0.2477],\n",
      "        [0.9985],\n",
      "        [0.7541],\n",
      "        [0.1468],\n",
      "        [0.2386]], grad_fn=<SigmoidBackward>)\u001b[0m\n",
      "\u001b[34mbatch_y (torch.Size([10])):\u001b[0m\n",
      "\u001b[34mtensor([1., 1., 0., 0., 1., 1., 1., 1., 0., 0.])\u001b[0m\n",
      "\u001b[34mEpoch: 42, Loss: 0.2681825927325657\u001b[0m\n",
      "\u001b[34m2022-05-11 04:50:01,555 sagemaker-containers INFO     Reporting training SUCCESS\u001b[0m\n",
      "\n",
      "2022-05-11 04:50:38 Completed - Training job completed\n",
      "Training seconds: 67\n",
      "Billable seconds: 67\n",
      "CPU times: user 727 ms, sys: 61.8 ms, total: 789 ms\n",
      "Wall time: 3min 43s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# Train your estimator on S3 training data\n",
    "estimator.fit({'training': input_data})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Deploy the trained model\n",
    "\n",
    "After training, deploy your model to create a `predictor`. If you're using a PyTorch model, you'll need to create a trained `PyTorchModel` that accepts the trained `<model>.model_data` as an input parameter and points to the provided `source_pytorch/predict.py` file as an entry point. \n",
    "\n",
    "To deploy a trained model, you'll use `<model>.deploy`, which takes in two arguments:\n",
    "* **initial_instance_count**: The number of deployed instances (1).\n",
    "* **instance_type**: The type of SageMaker instance for deployment.\n",
    "\n",
    "Note: If you run into an instance error, it may be because you chose the wrong training or deployment instance_type. It may help to refer to your previous exercise code to see which types of instances we used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----!CPU times: user 274 ms, sys: 29.9 ms, total: 304 ms\n",
      "Wall time: 2min 31s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# deploy your model to create a predictor\n",
    "# from sagemaker.predictor import RealTimePredictor\n",
    "from sagemaker.pytorch import PyTorchModel\n",
    "\n",
    "\n",
    "# class StringPredictor(RealTimePredictor):\n",
    "#     def __init__(self, endpoint_name, sagemaker_session):\n",
    "#         super(StringPredictor, self).__init__(endpoint_name, sagemaker_session, content_type='text/plain')\n",
    "\n",
    "model = PyTorchModel(model_data=estimator.model_data,\n",
    "                     role = role,\n",
    "                     framework_version='1.0',\n",
    "                     py_version='py3',\n",
    "                     entry_point='predict.py',\n",
    "                     source_dir=\"source_pytorch\")\n",
    "#                      predictor_cls=StringPredictor)\n",
    "predictor = model.deploy(initial_instance_count=1, instance_type='ml.m4.xlarge')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Evaluating Your Model\n",
    "\n",
    "Once your model is deployed, you can see how it performs when applied to our test data.\n",
    "\n",
    "The provided cell below, reads in the test data, assuming it is stored locally in `data_dir` and named `test.csv`. The labels and features are extracted from the `.csv` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "import os\n",
    "\n",
    "# read in test data, assuming it is stored locally\n",
    "test_data = pd.read_csv(os.path.join(data_dir, \"test.csv\"), header=None, names=None)\n",
    "\n",
    "# labels are in the first column\n",
    "test_y = test_data.iloc[:,0]\n",
    "test_x = test_data.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EXERCISE: Determine the accuracy of your model\n",
    "\n",
    "Use your deployed `predictor` to generate predicted, class labels for the test data. Compare those to the *true* labels, `test_y`, and calculate the accuracy as a value between 0 and 1.0 that indicates the fraction of test data that your model classified correctly. You may use [sklearn.metrics](https://scikit-learn.org/stable/modules/classes.html#module-sklearn.metrics) for this calculation.\n",
    "\n",
    "**To pass this project, your model should get at least 90% test accuracy.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "           1         2         3\n",
      "0   1.000000  0.943299  0.820755\n",
      "1   0.544503  0.005319  0.242574\n",
      "2   0.329502  0.003876  0.161172\n",
      "3   0.765306  0.625430  0.621711\n",
      "4   0.884444  0.247748  0.597458\n",
      "5   0.619048  0.075269  0.427835\n",
      "6   0.516129  0.000000  0.270833\n",
      "7   0.440860  0.005464  0.223958\n",
      "8   0.920000  0.472222  0.775000\n",
      "9   0.441176  0.000000  0.305556\n",
      "10  0.488889  0.000000  0.282609\n",
      "11  0.992674  0.977778  0.993056\n",
      "12  0.611111  0.000000  0.324675\n",
      "13  0.412698  0.000000  0.346667\n",
      "14  0.634021  0.020942  0.368932\n",
      "15  0.582938  0.134615  0.416667\n",
      "16  0.637931  0.323144  0.489879\n",
      "17  0.687764  0.141026  0.516393\n",
      "18  0.676647  0.140244  0.472527\n",
      "19  0.769231  0.459459  0.606452\n",
      "20  0.780000  0.619289  0.669903\n",
      "21  0.665025  0.230000  0.349265\n",
      "22  0.728155  0.064039  0.347619\n",
      "23  0.407035  0.005102  0.172249\n",
      "24  0.492891  0.000000  0.235023\n"
     ]
    }
   ],
   "source": [
    "print(type(test_x))\n",
    "print(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    1.000000\n",
      "2    0.943299\n",
      "3    0.820755\n",
      "Name: 0, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# for x in test_x:\n",
    "#     print(type(str(x)))\n",
    "#     print(str(x))\n",
    "    \n",
    "for index, row in test_x.iterrows():\n",
    "    print(str(row))\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test passed!\n"
     ]
    }
   ],
   "source": [
    "# First: generate predicted, class labels\n",
    "test_y_preds = []\n",
    "\n",
    "for idx, x in test_x.iterrows():\n",
    "    test_y_preds.append(int(predictor.predict(x)))\n",
    "\n",
    "test_y_preds = pd.Series(test_y_preds)\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL THAT IS BELOW THIS LINE\n",
    "\"\"\"\n",
    "# test that your model generates the correct number of labels\n",
    "assert len(test_y_preds)==len(test_y), 'Unexpected number of predictions.'\n",
    "print('Test passed!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(type(test_y_preds))\n",
    "\n",
    "print(type(test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_s: 0.96\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Second: calculate the test accuracy\n",
    "accuracy_s = accuracy_score(test_y, test_y_preds)\n",
    "print(f\"accuracy_s: {accuracy_s}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y = test_y.to_numpy()\n",
    "test_y_preds = test_y_preds.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0]\n",
      "[1 0 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0]\n",
      "[ True False False  True  True  True False False  True False False  True\n",
      " False False False  True  True  True  True  True  True  True  True False\n",
      " False]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "print(test_y)\n",
    "print(test_y_preds)\n",
    "print(np.logical_and(test_y, test_y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positive: 14\n",
      "False Positive: 0\n",
      "True Negative: 10\n",
      "False Negative: 1\n"
     ]
    }
   ],
   "source": [
    "tp = np.logical_and(test_y, test_y_preds).sum()\n",
    "fp = np.logical_and(1-test_y, test_y_preds).sum()\n",
    "tn = np.logical_and(1-test_y, 1-test_y_preds).sum()\n",
    "fn = np.logical_and(test_y, 1-test_y_preds).sum()\n",
    "\n",
    "print(f\"True Positive: {tp}\")\n",
    "print(f\"False Positive: {fp}\")\n",
    "print(f\"True Negative: {tn}\")\n",
    "print(f\"False Negative: {fn}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recall: 0.9333333333333333\n",
      "precision: 1.0\n",
      "accuracy: 0.96\n",
      "\n",
      "Predicted class labels: \n",
      "[1 0 0 1 1 1 0 0 1 0 0 1 0 0 0 1 1 1 1 1 1 1 1 0 0]\n",
      "\n",
      "True class labels: \n",
      "[1 0 0 1 1 1 0 0 1 0 0 1 0 0 1 1 1 1 1 1 1 1 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "recall = tp / (tp + fn)\n",
    "precision = tp / (tp + fp)\n",
    "accuracy = (tp + tn) / (tp + fp + tn + fn)\n",
    "\n",
    "# High recall is getting almost all cases of plagiarism with high false positives (detect plagiarism but is not)\n",
    "print(f\"recall: {recall}\")\n",
    "print(f\"precision: {precision}\")\n",
    "print(f\"accuracy: {accuracy}\")\n",
    "\n",
    "## print out the array of predicted and true labels, if you want\n",
    "print('\\nPredicted class labels: ')\n",
    "print(test_y_preds)\n",
    "print('\\nTrue class labels: ')\n",
    "print(test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: How many false positives and false negatives did your model produce, if any? And why do you think this is?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Answer**: \n",
    "False Positive: 0\n",
    "False Negative: 1\n",
    "\n",
    "The dataset was too small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2: How did you decide on the type of model to use? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Answer**:\n",
    "\n",
    "A RNN has been proven to work well on binary classification, as has been shown on fraudulent transaction notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "## EXERCISE: Clean up Resources\n",
    "\n",
    "After you're done evaluating your model, **delete your model endpoint**. You can do this with a call to `.delete_endpoint()`. You need to show, in this notebook, that the endpoint was deleted. Any other resources, you may delete from the AWS console, and you will find more instructions on cleaning up all your resources, below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment and fill in the line below!\n",
    "# <name_of_deployed_predictor>.delete_endpoint()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting S3 bucket\n",
    "\n",
    "When you are *completely* done with training and testing models, you can also delete your entire S3 bucket. If you do this before you are done training your model, you'll have to recreate your S3 bucket and upload your training data again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/boto3/compat.py:88: PythonDeprecationWarning: Boto3 will no longer support Python 3.6 starting May 30, 2022. To continue receiving service updates, bug fixes, and security updates please upgrade to Python 3.7 or later. More information can be found here: https://aws.amazon.com/blogs/developer/python-support-policy-updates-for-aws-sdks-and-tools/\n",
      "  warnings.warn(warning, PythonDeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'ResponseMetadata': {'RequestId': '63RSP4WYF9D05497',\n",
       "   'HostId': 'Dll4fo0lFGivBUGOujZiNyOg6uDYUMOqR0dkWpTLxEo/V7fPv2pHVcSEpmCZMWTAiJxamMP3JPY=',\n",
       "   'HTTPStatusCode': 200,\n",
       "   'HTTPHeaders': {'x-amz-id-2': 'Dll4fo0lFGivBUGOujZiNyOg6uDYUMOqR0dkWpTLxEo/V7fPv2pHVcSEpmCZMWTAiJxamMP3JPY=',\n",
       "    'x-amz-request-id': '63RSP4WYF9D05497',\n",
       "    'date': 'Wed, 11 May 2022 05:08:53 GMT',\n",
       "    'content-type': 'application/xml',\n",
       "    'transfer-encoding': 'chunked',\n",
       "    'server': 'AmazonS3',\n",
       "    'connection': 'close'},\n",
       "   'RetryAttempts': 0},\n",
       "  'Deleted': [{'Key': 'pytorch-training-2022-05-11-02-08-32-273/profiler-output/system/incremental/2022051102/1652235120.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/output/model.tar.gz'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/StepOutlier.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-report.ipynb'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/OverallFrameworkMetrics.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/OverallSystemUsage.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/rule-output/ProfilerReport-1652244434/profiler-output/profiler-reports/GPUMemoryIncrease.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/IOBottleneck.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/debug-output/collections/000000000/worker_0_collections.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/StepOutlier.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/MaxInitializationTime.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/BatchSize.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/profiler-output/system/incremental/2022051104/1652244180.algo-1.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-report.ipynb'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-43-08-585/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/LoadBalancing.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/LowGPUUtilization.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/LoadBalancing.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/rule-output/ProfilerReport-1652244434/profiler-output/profiler-reports/Dataloader.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-01-21-130/profiler-output/system/incremental/2022051102/1652234640.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/rule-output/ProfilerReport-1652244434/profiler-output/profiler-reports/CPUBottleneck.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/LowGPUUtilization.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/OverallFrameworkMetrics.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/LoadBalancing.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/LowGPUUtilization.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/CPUBottleneck.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/StepOutlier.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/MaxInitializationTime.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/Dataloader.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/GPUMemoryIncrease.json'},\n",
       "   {'Key': 'plagiarism/train.csv'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-report.ipynb'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/LowGPUUtilization.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/MaxInitializationTime.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/LowGPUUtilization.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/rule-output/ProfilerReport-1652244434/profiler-output/profiler-reports/OverallSystemUsage.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/Dataloader.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/GPUMemoryIncrease.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/profiler-output/system/incremental/2022051102/1652235780.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-report.html'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/rule-output/ProfilerReport-1652244434/profiler-output/profiler-reports/LoadBalancing.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/OverallFrameworkMetrics.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/rule-output/ProfilerReport-1652244434/profiler-output/profiler-reports/LowGPUUtilization.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/OverallSystemUsage.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/OverallFrameworkMetrics.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/OverallSystemUsage.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/GPUMemoryIncrease.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/Dataloader.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/IOBottleneck.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-43-08-585/output/model.tar.gz'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-45-01-079/sourcedir.tar.gz'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/CPUBottleneck.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/output/model.tar.gz'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/StepOutlier.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-report.html'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-report.html'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/Dataloader.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/profiler-output/system/incremental/2022051102/1652236500.algo-1.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/OverallSystemUsage.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-report.html'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/LoadBalancing.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/profiler-output/system/incremental/2022051102/1652235840.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/MaxInitializationTime.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/profiler-output/system/incremental/2022051102/1652236560.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/rule-output/ProfilerReport-1652244434/profiler-output/profiler-reports/IOBottleneck.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/profiler-output/system/incremental/2022051104/1652242740.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-report.html'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-01-21-130/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/LoadBalancing.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/LoadBalancing.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/profiler-output/system/incremental/2022051102/1652236140.algo-1.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/CPUBottleneck.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-report.ipynb'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-report.ipynb'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/rule-output/ProfilerReport-1652244434/profiler-output/profiler-report.ipynb'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/Dataloader.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/profiler-output/system/incremental/2022051102/1652235240.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/output/model.tar.gz'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/profiler-output/system/incremental/2022051102/1652236080.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/OverallFrameworkMetrics.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/profiler-output/system/incremental/2022051102/1652237160.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/BatchSize.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/profiler-output/system/incremental/2022051104/1652244600.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-01-01-215/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/profiler-output/system/incremental/2022051102/1652236200.algo-1.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/CPUBottleneck.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/CPUBottleneck.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-01-21-130/profiler-output/system/incremental/2022051102/1652234580.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/IOBottleneck.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/IOBottleneck.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/CPUBottleneck.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/Dataloader.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-report.ipynb'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/BatchSize.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/rule-output/ProfilerReport-1652244434/profiler-output/profiler-reports/MaxInitializationTime.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/OverallFrameworkMetrics.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-50-58-192/sourcedir.tar.gz'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-report.html'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/OverallSystemUsage.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/profiler-output/system/incremental/2022051102/1652236200.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-43-08-585/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-report.html'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/IOBottleneck.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/rule-output/ProfilerReport-1652244434/profiler-output/profiler-report.html'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/MaxInitializationTime.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/IOBottleneck.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/Dataloader.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/LowGPUUtilization.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/StepOutlier.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/StepOutlier.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/MaxInitializationTime.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-43-08-585/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-report.ipynb'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/rule-output/ProfilerReport-1652242672/profiler-output/profiler-reports/StepOutlier.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/profiler-output/system/incremental/2022051104/1652244540.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/profiler-output/system/incremental/2022051104/1652244240.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/profiler-output/system/incremental/2022051102/1652237220.algo-1.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/profiler-output/system/incremental/2022051102/1652235180.algo-1.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/profiler-output/system/incremental/2022051102/1652235900.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/CPUBottleneck.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/CPUBottleneck.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-01-21-130/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/OverallFrameworkMetrics.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-43-08-585/profiler-output/framework/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/profiler-output/system/incremental/2022051102/1652236140.algo-1.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/BatchSize.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/Dataloader.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/rule-output/ProfilerReport-1652244434/profiler-output/profiler-reports/StepOutlier.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/GPUMemoryIncrease.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/output/model.tar.gz'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/BatchSize.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/LoadBalancing.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/GPUMemoryIncrease.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/StepOutlier.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/OverallSystemUsage.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/MaxInitializationTime.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/BatchSize.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/OverallSystemUsage.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/LoadBalancing.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/BatchSize.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/LowGPUUtilization.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/profiler-output/system/incremental/2022051102/1652236440.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/OverallFrameworkMetrics.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/rule-output/ProfilerReport-1652237074/profiler-output/profiler-reports/IOBottleneck.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-reports/GPUMemoryIncrease.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/profiler-output/system/incremental/2022051102/1652236080.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-01-21-130/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-43-08-585/profiler-output/system/incremental/2022051102/1652237100.algo-1.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/source/sourcedir.tar.gz'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-50-59-410/sourcedir.tar.gz'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/GPUMemoryIncrease.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-44-34-046/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-08-32-273/rule-output/ProfilerReport-1652234912/profiler-output/profiler-report.ipynb'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/rule-output/ProfilerReport-1652244077/profiler-output/profiler-reports/BatchSize.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-44-335/rule-output/ProfilerReport-1652235944/profiler-output/profiler-reports/IOBottleneck.json'},\n",
       "   {'Key': 'plagiarism/test.csv'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/MaxInitializationTime.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-17-52-619/profiler-output/system/incremental/2022051104/1652242800.algo-1.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-reports/GPUMemoryIncrease.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/rule-output/ProfilerReport-1652235620/profiler-output/profiler-reports/LowGPUUtilization.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-32-20-920/rule-output/ProfilerReport-1652236341/profiler-output/profiler-report.html'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/rule-output/ProfilerReport-1652244434/profiler-output/profiler-reports/OverallFrameworkMetrics.json'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-25-51-667/rule-output/ProfilerReport-1652235951/profiler-output/profiler-reports/OverallSystemUsage.json'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-02-01-21-130/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-41-17-625/profiler-output/system/training_job_end.ts'},\n",
       "   {'Key': 'pytorch-training-2022-05-11-02-20-20-627/debug-output/training_job_end.ts'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-03-20-08-071/sourcedir.tar.gz'},\n",
       "   {'Key': 'sagemaker-pytorch-2022-05-11-04-47-14-375/rule-output/ProfilerReport-1652244434/profiler-output/profiler-reports/BatchSize.json'}]}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# deleting bucket, uncomment lines below\n",
    "\n",
    "bucket_to_delete = boto3.resource('s3').Bucket(bucket)\n",
    "bucket_to_delete.objects.all().delete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deleting all your models and instances\n",
    "\n",
    "When you are _completely_ done with this project and do **not** ever want to revisit this notebook, you can choose to delete all of your SageMaker notebook instances and models by following [these instructions](https://docs.aws.amazon.com/sagemaker/latest/dg/ex1-cleanup.html). Before you delete this notebook instance, I recommend at least downloading a copy and saving it, locally."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Further Directions\n",
    "\n",
    "There are many ways to improve or add on to this project to expand your learning or make this more of a unique project for you. A few ideas are listed below:\n",
    "* Train a classifier to predict the *category* (1-3) of plagiarism and not just plagiarized (1) or not (0).\n",
    "* Utilize a different and larger dataset to see if this model can be extended to other types of plagiarism.\n",
    "* Use language or character-level analysis to find different (and more) similarity features.\n",
    "* Write a complete pipeline function that accepts a source text and submitted text file, and classifies the submitted text as plagiarized or not.\n",
    "* Use API Gateway and a lambda function to deploy your model to a web application.\n",
    "\n",
    "These are all just options for extending your work. If you've completed all the exercises in this notebook, you've completed a real-world application, and can proceed to submit your project. Great job!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
